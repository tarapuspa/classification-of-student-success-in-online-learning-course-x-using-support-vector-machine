{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM 0.8_percobaan1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmfQa-3RUxZS"
      },
      "source": [
        "# BAGIAN IMPORT #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e6c-A4IU4qz"
      },
      "source": [
        "import pandas  as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import pandas as pd # to import csv and for data manipulation\n",
        "import matplotlib.pyplot as plt # to plot graph\n",
        "import seaborn as sns # for intractve graphs\n",
        "import numpy as np # for linear algebra\n",
        "import datetime # to dela with date and time\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import StandardScaler # for preprocessing the data\n",
        "from sklearn.svm import SVC # for SVM classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold # For cross validation\n",
        "from sklearn.model_selection import GridSearchCV # for tunnig hyper parameter it will use all combination of given parameters\n",
        "from sklearn.model_selection import RandomizedSearchCV # same for tunning hyper parameter but will use random combinations of parameters\n",
        "from sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "FoiHCgK0VrZx",
        "outputId": "139a9a7e-b0b3-4420-e7ee-9330f4f08310"
      },
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c600cbb1-6a0b-44c9-9cab-80139a7e6095\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c600cbb1-6a0b-44c9-9cab-80139a7e6095\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data_log_mk_x.csv to data_log_mk_x.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da_iElvWVrZ2",
        "outputId": "4e3aa4d0-4c8f-430e-f48d-e2662a5bc03a"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data_log_mk_x.csv') \n",
        "print (df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     A submission has been submitted  ...  Status Kelulusan\n",
            "0                                  5  ...                 1\n",
            "1                                  6  ...                 1\n",
            "2                                  7  ...                 1\n",
            "3                                  3  ...                 1\n",
            "4                                  5  ...                 1\n",
            "..                               ...  ...               ...\n",
            "227                                3  ...                 1\n",
            "228                                5  ...                 1\n",
            "229                                4  ...                 1\n",
            "230                                4  ...                 1\n",
            "231                                3  ...                 1\n",
            "\n",
            "[232 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6f2paCyfvqu"
      },
      "source": [
        "\n",
        "# Pre-processing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdxUxC5BWaF8",
        "outputId": "15b9d8e0-b809-45bc-bf0d-148c52443d9c"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 232 entries, 0 to 231\n",
            "Data columns (total 13 columns):\n",
            " #   Column                                        Non-Null Count  Dtype\n",
            "---  ------                                        --------------  -----\n",
            " 0   A submission has been submitted               232 non-null    int64\n",
            " 1   Course activity completion updated            232 non-null    int64\n",
            " 2   Course module viewed                          232 non-null    int64\n",
            " 3   Course viewed                                 232 non-null    int64\n",
            " 4   Discussion viewed                             232 non-null    int64\n",
            " 5   Quiz attempt started                          232 non-null    int64\n",
            " 6   Quiz attempt submitted                        232 non-null    int64\n",
            " 7   Some content has been posted.                 232 non-null    int64\n",
            " 8   The status of the submission has been viewed  232 non-null    int64\n",
            " 9   User graded                                   232 non-null    int64\n",
            " 10  File                                          232 non-null    int64\n",
            " 11  URL                                           232 non-null    int64\n",
            " 12  Status Kelulusan                              232 non-null    int64\n",
            "dtypes: int64(13)\n",
            "memory usage: 23.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XJCW_t9W4R7",
        "outputId": "3348ec3c-7211-4211-ccec-2894f8930247"
      },
      "source": [
        "df['Status Kelulusan'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    219\n",
              "0     13\n",
              "Name: Status Kelulusan, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "Y1GLHR-oWeGh",
        "outputId": "e35411ac-0a0c-4ac4-83bf-4ce7ffbd7a0f"
      },
      "source": [
        "pd.value_counts(df['Status Kelulusan']).plot.bar()\n",
        "plt.title('Histogram Status Kelulusan')\n",
        "plt.xlabel('Status Kelulusan')\n",
        "plt.ylabel('Frequency')\n",
        "df['Status Kelulusan'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    219\n",
              "0     13\n",
              "Name: Status Kelulusan, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npRSU6BfWlD5",
        "outputId": "69087225-3526-457d-db12-0317cacbdac8"
      },
      "source": [
        "# Untuk memeriksa persentase dari tiap kategori\n",
        "Count_Lulus = len(df[df[\"Status Kelulusan\"]==1]) # lulus\n",
        "Count_Tidak_Lulus = len(df[df[\"Status Kelulusan\"]==0]) # tidak lulus by 1\n",
        "Percentage_of_lulus = Count_Lulus/(Count_Lulus+Count_Tidak_Lulus)\n",
        "print(\"persentase dari lulus\",Percentage_of_lulus*100)\n",
        "Percentage_of_Tidak_Lulus= Count_Tidak_Lulus/(Count_Lulus+Count_Tidak_Lulus)\n",
        "print(\"persentase dari tidak lulus\",Percentage_of_Tidak_Lulus*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "persentase dari lulus 94.39655172413794\n",
            "persentase dari tidak lulus 5.603448275862069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY7UU6kAqFQS",
        "outputId": "b44ea01a-e642-45a4-c8f2-d265a5b44d24"
      },
      "source": [
        "# untuk memeriksa apakah ada missing value\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A submission has been submitted                 0\n",
              "Course activity completion updated              0\n",
              "Course module viewed                            0\n",
              "Course viewed                                   0\n",
              "Discussion viewed                               0\n",
              "Quiz attempt started                            0\n",
              "Quiz attempt submitted                          0\n",
              "Some content has been posted.                   0\n",
              "The status of the submission has been viewed    0\n",
              "User graded                                     0\n",
              "File                                            0\n",
              "URL                                             0\n",
              "Status Kelulusan                                0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoazgyslaElM"
      },
      "source": [
        "# untuk membagi variabel dalam data menjadi fitur (X) dan variabel target (y)\n",
        "X = df.drop(['Status Kelulusan'], axis=1)\n",
        "\n",
        "y = df['Status Kelulusan']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFehvw8_aElc"
      },
      "source": [
        "# membagi X dan y dalam data latih dan data uji, dengan proporsi 0,8 data uji dan 0,2 data latih\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2oXCmp8aEld",
        "outputId": "16488633-e84a-459d-f36e-c4f1230cb884"
      },
      "source": [
        "# memeriksa jumlah data latih dan data uji\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((185, 12), (47, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti7QT91Muw7O",
        "outputId": "504e1677-0d87-45e8-99e9-c07387dee721"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    42\n",
              "0     5\n",
              "Name: Status Kelulusan, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMnVqiA2aEle"
      },
      "source": [
        "cols = X_train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PDuEHpfaElf"
      },
      "source": [
        "# untuk standarisasi, dengan melakukan penyesuaian skala pada data uji\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjd0PS_vaElf"
      },
      "source": [
        "X_train = pd.DataFrame(X_train, columns=[cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_UVcXxyaElf"
      },
      "source": [
        "X_test = pd.DataFrame(X_test, columns=[cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "hwKFtO9ZaMyG",
        "outputId": "5e47b1b6-a0a6-4a47-943a-2cc789ca84fc"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>A submission has been submitted</th>\n",
              "      <th>Course activity completion updated</th>\n",
              "      <th>Course module viewed</th>\n",
              "      <th>Course viewed</th>\n",
              "      <th>Discussion viewed</th>\n",
              "      <th>Quiz attempt started</th>\n",
              "      <th>Quiz attempt submitted</th>\n",
              "      <th>Some content has been posted.</th>\n",
              "      <th>The status of the submission has been viewed</th>\n",
              "      <th>User graded</th>\n",
              "      <th>File</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.009319</td>\n",
              "      <td>1.770466</td>\n",
              "      <td>2.662086</td>\n",
              "      <td>1.011214</td>\n",
              "      <td>0.703961</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.811401</td>\n",
              "      <td>2.598332</td>\n",
              "      <td>0.143393</td>\n",
              "      <td>3.854295</td>\n",
              "      <td>3.695699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.421679</td>\n",
              "      <td>-2.067782</td>\n",
              "      <td>-0.252793</td>\n",
              "      <td>0.519746</td>\n",
              "      <td>0.286206</td>\n",
              "      <td>0.696558</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>0.462182</td>\n",
              "      <td>0.505589</td>\n",
              "      <td>0.790413</td>\n",
              "      <td>-0.334336</td>\n",
              "      <td>-1.078772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.871314</td>\n",
              "      <td>-1.842002</td>\n",
              "      <td>-1.338728</td>\n",
              "      <td>-1.287860</td>\n",
              "      <td>-1.189267</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-1.100852</td>\n",
              "      <td>-0.947705</td>\n",
              "      <td>0.790413</td>\n",
              "      <td>0.619741</td>\n",
              "      <td>-0.123878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.852677</td>\n",
              "      <td>-0.157341</td>\n",
              "      <td>0.118711</td>\n",
              "      <td>-0.796391</td>\n",
              "      <td>-0.495972</td>\n",
              "      <td>0.696558</td>\n",
              "      <td>0.756232</td>\n",
              "      <td>-0.348280</td>\n",
              "      <td>-0.075728</td>\n",
              "      <td>0.790413</td>\n",
              "      <td>0.363769</td>\n",
              "      <td>-0.497532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.440317</td>\n",
              "      <td>-0.209444</td>\n",
              "      <td>-0.002742</td>\n",
              "      <td>0.902925</td>\n",
              "      <td>-0.451530</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.927181</td>\n",
              "      <td>0.389326</td>\n",
              "      <td>0.143393</td>\n",
              "      <td>-0.799739</td>\n",
              "      <td>-0.248430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  A submission has been submitted  ...       URL\n",
              "0                       -0.009319  ...  3.695699\n",
              "1                        0.421679  ... -1.078772\n",
              "2                       -0.871314  ... -0.123878\n",
              "3                        0.852677  ... -0.497532\n",
              "4                       -0.440317  ... -0.248430\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WR28FGMe6hD",
        "outputId": "53599adc-9a2b-47ce-b36f-e3a37c4594bc"
      },
      "source": [
        "# untuk mengecek kembali banyaknya observasi dan dimensi pada fitur (X) dan variabel target (y)\n",
        "X, y = df.iloc[:, :-1], df.iloc[:, [-1]]\n",
        "print('Dimensi dari X: {}'.format(X.shape))\n",
        "print('Dimensi dari y: {}'.format(y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensi dari X: (232, 12)\n",
            "Dimensi dari y: (232, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2YCYvrEaReF",
        "outputId": "f9974caa-92dc-46bf-f0a8-8068d5df3915"
      },
      "source": [
        "# untuk melihat banyaknya observasi dan dimensi fitur (X) dan variabel target (y) pada data latih dan data uji\n",
        "print(\"Jumlah Kelulusan X_train dataset: \", X_train.shape)\n",
        "print(\"Jumlah Kelulusan y_train dataset: \", y_train.shape)\n",
        "print(\"Jumlah Kelulusan X_test dataset: \", X_test.shape)\n",
        "print(\"Jumlah Kelulusan y_test dataset: \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah Kelulusan X_train dataset:  (185, 12)\n",
            "Jumlah Kelulusan y_train dataset:  (185,)\n",
            "Jumlah Kelulusan X_test dataset:  (47, 12)\n",
            "Jumlah Kelulusan y_test dataset:  (47,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ2MS3bxf89a"
      },
      "source": [
        "\n",
        "# SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hzp9SNSRyjM",
        "outputId": "bbfb9954-8d4f-4280-e406-d2853c307fe7"
      },
      "source": [
        "# melihat banyaknya data antar label, sebelum dilakukan oversampling\n",
        "print(\"Sebelum OverSampling, jumlah dari label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Sebelum OverSampling, jumlah dari label '0': {} \\n\".format(sum(y_train==0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sebelum OverSampling, jumlah dari label '1': 177\n",
            "Sebelum OverSampling, jumlah dari label '0': 8 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTMjfrmGa7TK"
      },
      "source": [
        "# pembangunan data sintetik untuk label '0' pada data latih menggunakan SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(k_neighbors=5, random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.values.ravel())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UaNP01reOLW",
        "outputId": "cfa661bb-57b4-4aab-8922-4432984b9a77"
      },
      "source": [
        "# hasil dari SMOTE\n",
        "print('Setelah OverSampling, dimensi dari train_X: {}'.format(X_train_res.shape))\n",
        "print('Setelah OverSampling, dimensi dari train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"Setelah OverSampling, jumlah dari label '1': {}\".format(sum(y_train_res==1)))\n",
        "print(\"Setelah OverSampling, jumlah dari label '0': {}\".format(sum(y_train_res==0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setelah OverSampling, dimensi dari train_X: (354, 12)\n",
            "Setelah OverSampling, dimensi dari train_y: (354,) \n",
            "\n",
            "Setelah OverSampling, jumlah dari label '1': 177\n",
            "Setelah OverSampling, jumlah dari label '0': 177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "skVGlNqYxvS-",
        "outputId": "bc902f97-f63e-4e9c-be4c-94fa3dfdcf4b"
      },
      "source": [
        "pd.value_counts(y_train).plot.bar()\n",
        "plt.title('Diagram Batang Status Kelulusan pada Data Latih 80 % Sebelum SMOTE')\n",
        "tick_label = ['Lulus', 'Tidak Lulus']\n",
        "plt.xlabel('Status Kelulusan')\n",
        "plt.ylabel('Frequency')\n",
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    177\n",
              "0      8\n",
              "Name: Status Kelulusan, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRm1lXyEriId",
        "outputId": "3f818627-d051-4532-f168-fd53534afa73"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77     1\n",
            "34     1\n",
            "142    1\n",
            "70     1\n",
            "101    1\n",
            "      ..\n",
            "129    1\n",
            "197    1\n",
            "183    1\n",
            "174    1\n",
            "122    1\n",
            "Name: Status Kelulusan, Length: 185, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "zw_MRuysjRhE",
        "outputId": "a14e525d-057e-41d2-b170-f71ba784337a"
      },
      "source": [
        "y_train.value_counts(sort=False).plot.bar(rot=0)\n",
        "plt.title('Diagram Batang Status Kelulusan pada Data Latih 80 % Sebelum SMOTE')\n",
        "plt.xlabel('Status Kelulusan')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Status Kelulusan')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "jZL0EJTMvt4n",
        "outputId": "b35be2db-67e9-46df-cf8a-b90639fc2410"
      },
      "source": [
        "pd.value_counts(y_train_res).plot.bar()\n",
        "plt.title('Diagram Batang Status Kelulusan pada Data Latih 80% Setelah SMOTE')\n",
        "plt.xlabel('Status Kelulusan')\n",
        "plt.ylabel('Frequency')\n",
        "y_train_res.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-404640ba12a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Diagram Batang Status Kelulusan pada Data Latih 80% Setelah SMOTE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Status Kelulusan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_counts_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_value_counts_arraylike\u001b[0;34m(values, dropna)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# TODO: handle uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"value_count_{ndtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_func_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.value_count_int64\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9bnkQ0WkuH_",
        "outputId": "0e43a7a6-3444-4c67-b437-2250eb12b3d1"
      },
      "source": [
        "print(y_train_res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p5ImjmIqaJ-"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create the dataframe\n",
        "y_train_res = pd.DataFrame(y_train_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAn2p57Xq7fx",
        "outputId": "25946719-9778-43a1-c898-8fb526db41c6"
      },
      "source": [
        "print(y_train_res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "..  ..\n",
            "349  0\n",
            "350  0\n",
            "351  0\n",
            "352  0\n",
            "353  0\n",
            "\n",
            "[354 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "tLXmhFtUjtfr",
        "outputId": "52113df9-d845-4fbe-a6aa-a309ce03253f"
      },
      "source": [
        "y_train_res.value_counts(sort=False).plot.bar(rot=0)\n",
        "plt.title('Diagram Batang Status Kelulusan pada Data Latih 80% Setelah SMOTE')\n",
        "plt.xlabel('Status Kelulusan')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Status Kelulusan')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ewU9om8nJaOM",
        "outputId": "5b994b8b-2526-4062-c267-d1806410e3a1"
      },
      "source": [
        "X_train_res = pd.DataFrame(X_train_res)\n",
        "X_train_res.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>-1.005635</td>\n",
              "      <td>-1.940559</td>\n",
              "      <td>-1.469692</td>\n",
              "      <td>-1.040682</td>\n",
              "      <td>-0.757340</td>\n",
              "      <td>-1.849482</td>\n",
              "      <td>-1.800341</td>\n",
              "      <td>-1.111624</td>\n",
              "      <td>-0.987192</td>\n",
              "      <td>-1.271044</td>\n",
              "      <td>-0.998574</td>\n",
              "      <td>-1.164131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>0.320053</td>\n",
              "      <td>1.117406</td>\n",
              "      <td>-0.438951</td>\n",
              "      <td>0.121135</td>\n",
              "      <td>-1.120460</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-1.264162</td>\n",
              "      <td>0.460673</td>\n",
              "      <td>0.637851</td>\n",
              "      <td>0.096824</td>\n",
              "      <td>0.447572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>-1.746689</td>\n",
              "      <td>-2.045447</td>\n",
              "      <td>-1.811710</td>\n",
              "      <td>-1.542044</td>\n",
              "      <td>-1.299239</td>\n",
              "      <td>-5.378211</td>\n",
              "      <td>-5.343669</td>\n",
              "      <td>-1.390302</td>\n",
              "      <td>-1.830508</td>\n",
              "      <td>-5.052846</td>\n",
              "      <td>-1.312251</td>\n",
              "      <td>-0.978708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>-0.995415</td>\n",
              "      <td>-0.915030</td>\n",
              "      <td>-1.333613</td>\n",
              "      <td>-0.999130</td>\n",
              "      <td>-1.286797</td>\n",
              "      <td>-3.475459</td>\n",
              "      <td>-3.433045</td>\n",
              "      <td>-1.370480</td>\n",
              "      <td>-0.963765</td>\n",
              "      <td>-3.038834</td>\n",
              "      <td>-0.810333</td>\n",
              "      <td>-0.470878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>-1.841121</td>\n",
              "      <td>-2.067801</td>\n",
              "      <td>-1.901402</td>\n",
              "      <td>-1.669040</td>\n",
              "      <td>-1.298151</td>\n",
              "      <td>-5.498869</td>\n",
              "      <td>-5.464826</td>\n",
              "      <td>-1.361341</td>\n",
              "      <td>-1.906928</td>\n",
              "      <td>-5.194607</td>\n",
              "      <td>-1.474680</td>\n",
              "      <td>-1.078843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2   ...        9         10        11\n",
              "349 -1.005635 -1.940559 -1.469692  ... -1.271044 -0.998574 -1.164131\n",
              "350  0.320053  1.117406 -0.438951  ...  0.637851  0.096824  0.447572\n",
              "351 -1.746689 -2.045447 -1.811710  ... -5.052846 -1.312251 -0.978708\n",
              "352 -0.995415 -0.915030 -1.333613  ... -3.038834 -0.810333 -0.470878\n",
              "353 -1.841121 -2.067801 -1.901402  ... -5.194607 -1.474680 -1.078843\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkYQCsb595QA",
        "outputId": "fd0f8728-965f-47f6-ffed-e7a16f3585cc"
      },
      "source": [
        "# importing the modules\n",
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(X_train_res)\n",
        "df.columns = ['A submission has been submitted', 'Course activity completion updated', 'Course module viewed', 'Course viewed','Discussion viewed','Quiz attempt started','Quiz attempt submitted','Some content has been posted','The status of the submission has been viewed','User graded','File','URL']\n",
        "# displaying the DataFrame\n",
        "print(tabulate(df, headers = 'keys', tablefmt = 'fancy_grid'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "        A submission has been submitted    Course activity completion updated    Course module viewed    Course viewed    Discussion viewed    Quiz attempt started    Quiz attempt submitted    Some content has been posted    The status of the submission has been viewed    User graded         File           URL \n",
            "\n",
            "   0                        -0.00931887                            1.77047                 2.66209          1.01121              0.703961                 0.14586                  0.203256                      -0.811401                                         2.59833        0.143393     3.8543       3.6957      \n",
            "\n",
            "   1                         0.421679                             -2.06778                -0.252793         0.519746             0.286206                 0.696558                 0.203256                       0.462182                                         0.505589       0.790413    -0.334336    -1.07877     \n",
            "\n",
            "   2                        -0.871314                             -1.842                  -1.33873         -1.28786             -1.18927                  0.14586                  0.203256                      -1.10085                                         -0.947705       0.790413     0.619741    -0.123878    \n",
            "\n",
            "   3                         0.852677                             -0.157341                0.118711        -0.796391            -0.495972                 0.696558                 0.756232                      -0.34828                                         -0.0757284      0.790413     0.363769    -0.497532    \n",
            "\n",
            "   4                        -0.440317                             -0.209444               -0.00274187       0.902925            -0.45153                  0.14586                  0.203256                      -0.927181                                         0.389326       0.143393    -0.799739    -0.24843     \n",
            "\n",
            "   5                        -1.73331                              -2.03305                -1.79596         -1.5211              -1.29593                 -5.36112                 -5.3265                        -1.3903                                          -1.81968       -5.03276     -1.28841     -0.954221    \n",
            "\n",
            "   6                         1.71467                               0.190011                2.59064          1.66095              3.91267                  0.14586                  0.203256                       2.37256                                          1.90075        0.143393     0.689552     0.540396    \n",
            "\n",
            "   7                        -0.440317                             -0.348385               -1.08868         -1.31285             -0.638187                 0.14586                  0.203256                      -0.811401                                        -0.598914       0.143393    -1.07898     -1.03726     \n",
            "\n",
            "   8                        -0.00931887                            1.38838                -0.38139          0.0949167           -0.691517                 0.14586                  0.203256                      -0.927181                                        -0.598914       0.143393    -0.241255     0.664947    \n",
            "\n",
            "   9                        -0.440317                              1.40575                -0.802905         0.0532668           -0.629298                -0.404837                -0.34972                       -0.34828                                         -0.482651      -0.503626    -1.14879     -0.082361    \n",
            "\n",
            "  10                        -0.00931887                            1.30154                -0.445689         0.236526            -0.380423                -1.50623                 -1.45567                       -0.52195                                         -0.773309      -1.79766     -0.93936      0.706465    \n",
            "\n",
            "  11                        -0.871314                              1.28417                 0.661679         0.236526            -0.238209                 0.14586                  0.203256                      -0.63773                                         -0.250124       0.143393     2.22538      0.789499    \n",
            "\n",
            "  12                        -0.440317                             -1.59886                -0.988657        -0.421542            -0.318204                -0.404837                -0.34972                       -0.985071                                        -0.250124       0.143393    -0.357606    -0.746635    \n",
            "\n",
            "  13                        -0.871314                             -0.105238               -0.438545        -0.663111            -0.771512                 0.14586                  0.203256                      -0.57984                                         -1.41276        0.790413     0.41031     -1.20332     \n",
            "\n",
            "  14                         0.421679                             -0.469959               -0.674307        -0.729751            -0.433754                 0.14586                  0.203256                      -0.57984                                          0.389326       0.143393    -0.00855336  -1.32788     \n",
            "\n",
            "  15                         4.30066                               0.27685                 1.26895          0.0532668            0.366202                 0.696558                 0.756232                       2.37256                                          1.02877        0.790413     2.20211      0.997085    \n",
            "\n",
            "  16                        -0.440317                              0.190011                1.17607          0.328156             2.57941                  0.14586                  0.203256                       2.08311                                          0.389326       0.143393     0.0845273    0.166742    \n",
            "\n",
            "  17                        -0.440317                              0.0858055               1.43326          1.33608              1.54836                  0.696558                 0.756232                       1.79366                                          1.4357         0.790413    -0.194715     0.457362    \n",
            "\n",
            "  18                         0.421679                              1.09313                 0.575947        -0.0300329            0.161769                 0.14586                  0.203256                       0.867414                                        -0.0757284      0.143393    -0.729929    -1.12029     \n",
            "\n",
            "  19                        -0.00931887                           -0.539429               -0.545709        -0.171643            -0.629298                 0.14586                  0.203256                      -0.811401                                        -0.366387       0.143393    -0.753199    -0.705118    \n",
            "\n",
            "  20                        -0.440317                             -0.487327               -0.4314          -0.438202            -0.558191                 0.14586                  0.203256                      -0.695621                                        -0.715178       0.143393    -0.473957    -0.871187    \n",
            "\n",
            "  21                         0.421679                             -0.192077                1.4547           3.43524              0.250653                 0.14586                  0.203256                       0.577963                                         2.24954        0.143393     0.224148     2.11805     \n",
            "\n",
            "  22                         0.421679                             -1.77253                -0.00274187      -0.288262            -0.291539                 0.696558                 0.756232                       0.0569514                                       -0.482651       0.790413     0.712822     0.125225    \n",
            "\n",
            "  23                        -0.871314                             -0.24418                 0.383051         0.503086             0.5973                   0.14586                  0.203256                      -0.116719                                         0.331194       0.143393     1.22477     -0.53905     \n",
            "\n",
            "  24                        -0.871314                             -0.0357679              -0.517132         0.0532668           -0.442642                 0.14586                  0.203256                      -0.232499                                        -0.947705       0.143393    -0.753199    -0.414498    \n",
            "\n",
            "  25                        -0.440317                             -0.296283                0.0472683       -0.163313             0.206211                 0.14586                  0.203256                      -0.63773                                         -0.308255       0.143393    -0.729929    -1.53546     \n",
            "\n",
            "  26                        -0.440317                             -0.331018               -1.1887          -1.37116             -1.00261                  0.14586                  0.203256                      -0.695621                                        -1.06397        0.143393    -0.84628     -1.49394     \n",
            "\n",
            "  27                        -0.00931887                            0.0858055               0.311608         0.336486             0.410644                 0.14586                  0.203256                       2.43045                                          0.447457       0.143393    -0.613578     2.40867     \n",
            "\n",
            "  28                        -0.00931887                            2.4478                  4.16239          3.08538              2.77496                  0.696558                 0.756232                      -0.811401                                         1.95888        0.790413     0.48012      0.872533    \n",
            "\n",
            "  29                        -0.440317                             -0.157341                0.261598        -0.446532             0.0817732                0.14586                 -0.34972                        0.809523                                         0.679984      -0.503626     0.992064     0.166742    \n",
            "\n",
            "  30                         1.28367                              -0.157341               -0.338524        -0.313252             0.09955                  0.696558                 0.756232                      -0.116719                                        -0.540782       0.790413    -0.148174    -0.580567    \n",
            "\n",
            "  31                        -0.871314                             -0.469959               -1.11011         -0.679771            -0.513749                 0.14586                  0.203256                      -0.811401                                        -1.41276        0.143393    -0.823009    -1.16181     \n",
            "\n",
            "  32                        -0.871314                             -0.122606               -0.538565        -0.588142             0.0373312                0.14586                  0.203256                       0.520073                                        -0.598914       0.143393    -0.729929     0.664947    \n",
            "\n",
            "  33                         0.852677                              0.137908               -0.638585        -0.846371            -1.0115                  -0.955535                -0.902696                      -0.927181                                         0.273062      -0.503626    -0.148174    -0.580567    \n",
            "\n",
            "  34                         0.421679                             -0.192077               -0.367102         0.0865868           -0.211544                 0.14586                  0.203256                       0.172732                                        -0.0175966      0.143393    -0.753199     0.872533    \n",
            "\n",
            "  35                         0.421679                             -0.122606                0.275886        -0.98798             -0.967057                 0.14586                  0.203256                      -0.985071                                         0.796248       0.143393     3.01657     -0.663601    \n",
            "\n",
            "  36                        -0.440317                             -0.400488               -1.06724         -1.07128             -0.647075                -0.404837                -0.34972                       -0.116719                                        -1.23836       -0.503626    -1.00917     -0.622084    \n",
            "\n",
            "  37                        -0.440317                              1.64889                -0.324236        -0.546492            -0.771512                -0.955535                -0.902696                      -0.695621                                         0.273062      -1.15065     -0.194715     0.291293    \n",
            "\n",
            "  38                        -0.440317                             -1.89411                -0.831482        -1.27953             -0.0959946                0.14586                  0.203256                      -0.57984                                         -0.657046       0.143393    -0.613578    -1.28636     \n",
            "\n",
            "  39                        -0.871314                              0.224747                0.554514        -0.629791             0.161769                 0.14586                  0.203256                      -0.34828                                         -0.250124       0.143393     1.4342       0.374328    \n",
            "\n",
            "  40                         0.421679                              1.64889                -0.0956179        0.444776            -0.647075                 0.14586                  0.203256                      -0.40617                                         -0.250124       0.143393    -0.0783639    0.415845    \n",
            "\n",
            "  41                        -2.16431                              -1.35571                -1.93885         -1.79599             -1.38481                 -5.91181                 -5.87948                       -1.3903                                          -1.99408       -5.67978     -1.35822     -1.49394     \n",
            "\n",
            "  42                         1.28367                              -0.747841               -0.33138          0.0199469           -0.17599                  0.14586                  0.203256                      -0.40617                                          0.621853       0.143393     0.363769    -0.746635    \n",
            "\n",
            "  43                        -0.871314                             -1.00836                -0.64573         -0.546492            -0.84262                 -1.50623                 -1.45567                       -0.985071                                        -0.13386       -1.15065      0.619741    -1.41091     \n",
            "\n",
            "  44                        -0.00931887                            0.172644               -0.817193        -0.013373            -0.735959                 0.14586                  0.203256                      -0.34828                                         -0.191992       0.143393    -0.776469    -0.954221    \n",
            "\n",
            "  45                         0.421679                             -1.39044                -0.167061         0.703005            -0.762624                 0.14586                  0.203256                      -0.40617                                          0.273062       0.143393     0.293959     0.789499    \n",
            "\n",
            "  46                        -0.871314                              0.0337026               0.168722        -0.271602             1.22838                  0.14586                  0.203256                       1.44632                                          0.156799       0.143393    -0.334336     1.37074     \n",
            "\n",
            "  47                         1.71467                               1.14523                 0.404484         0.852945             0.268429                 0.14586                 -0.34972                        0.693743                                         1.14504       -0.503626     0.363769     1.45377     \n",
            "\n",
            "  48                        -0.440317                             -0.122606               -0.674307         0.219866            -0.12266                  0.14586                  0.203256                      -0.695621                                        -0.947705       0.790413    -1.07898     -0.622084    \n",
            "\n",
            "  49                        -0.440317                             -0.661003               -0.945791        -0.621461            -0.931504                 0.14586                  0.203256                      -0.811401                                        -0.715178       0.143393    -0.89282     -1.03726     \n",
            "\n",
            "  50                        -0.440317                             -0.139974                0.518793         1.38606              0.828398                 0.696558                 0.756232                      -0.116719                                        -0.13386        0.790413    -0.124904     0.664947    \n",
            "\n",
            "  51                        -0.00931887                            1.42311                -0.0170305       -0.288262            -0.113771                 0.14586                  0.203256                      -0.40617                                          0.0405351      0.143393    -0.217985     0.91405     \n",
            "\n",
            "  52                         2.57667                               0.27685                 0.790277         0.986224             0.455086                 0.696558                 0.756232                       0.751633                                         0.621853       0.790413     2.31846      0.291293    \n",
            "\n",
            "  53                        -0.871314                              0.328952               -0.802905        -1.13792             -0.567079                 0.696558                 0.756232                      -0.57984                                         -1.23836        0.790413    -0.287795    -0.746635    \n",
            "\n",
            "  54                         1.28367                              -0.31365                -0.74575         -0.446532            -0.655963                 0.14586                  0.203256                      -0.34828                                         -0.598914       0.143393     0.0147168   -0.53905     \n",
            "\n",
            "  55                        -0.00931887                           -0.661003               -1.18155         -1.24621             -0.540414                 0.14586                  0.203256                       0.230622                                        -1.18023        0.143393    -0.357606    -0.788152    \n",
            "\n",
            "  56                         0.421679                             -0.157341                0.404484         0.869605             0.277318                 0.14586                  0.203256                      -0.46406                                          0.679984       0.143393    -0.0783639   -0.372981    \n",
            "\n",
            "  57                        -0.440317                             -0.331018                0.111567         1.63596             -0.113771                 0.14586                  0.203256                      -0.29039                                          1.08691        0.143393    -0.497227    -0.53905     \n",
            "\n",
            "  58                        -0.00931887                            0.0858055              -1.0601          -0.854701            -0.300428                 0.696558                 0.756232                       1.15686                                         -0.424519       0.790413    -0.776469    -0.995738    \n",
            "\n",
            "  59                        -0.440317                              1.1105                 -0.00988618      -0.304922            -0.309316                 0.14586                  0.203256                      -0.753511                                        -0.250124       0.143393    -0.311066     1.49529     \n",
            "\n",
            "  60                         0.421679                              1.23207                -0.445689         0.00328696          -1.26926                  0.14586                  0.203256                      -1.33241                                          0.679984       0.790413     0.107798     0.457362    \n",
            "\n",
            "  61                         1.28367                              -1.00836                -0.295659        -0.771401            -0.0959946                0.696558                 0.756232                       0.230622                                        -0.308255       0.790413    -0.357606     0.125225    \n",
            "\n",
            "  62                        -0.00931887                            1.17997                 1.26895          1.41938             -0.371535                 0.14586                  0.203256                      -0.0588289                                        1.2613         0.143393     0.596471     0.91405     \n",
            "\n",
            "  63                         0.421679                             -0.417856               -0.867203        -0.771401            -0.655963                 0.14586                  0.203256                      -0.52195                                         -0.366387       0.143393    -0.96263     -0.705118    \n",
            "\n",
            "  64                        -0.440317                             -0.365753               -0.424256        -0.946331             0.695072                 0.14586                  0.203256                      -0.63773                                         -1.00584        0.143393    -0.567037    -0.24843     \n",
            "\n",
            "  65                        -0.871314                             -0.522062                3.93377          4.13496              3.53047                  0.14586                  0.203256                       1.21475                                         -0.482651       0.143393     2.78387      1.12164     \n",
            "\n",
            "  66                        -0.00931887                            0.207379                2.16913          3.19367              1.15727                 -0.404837                -0.34972                       -0.52195                                          2.65646       -0.503626     2.85368      0.166742    \n",
            "\n",
            "  67                        -0.440317                             -1.51202                -0.917214         0.603045            -0.371535                 0.14586                  0.203256                      -0.695621                                         0.0405351      0.143393    -1.47457      0.000673251 \n",
            "\n",
            "  68                        -0.871314                             -0.157341                0.783132         0.194876             1.90389                  0.14586                  0.203256                       0.288512                                        -0.947705       0.143393     1.06187      0.457362    \n",
            "\n",
            "  69                         0.421679                              1.2668                  1.00461          1.57765              0.366202                 0.696558                 0.203256                       0.172732                                         0.505589       0.143393     0.293959     1.08012     \n",
            "\n",
            "  70                        -0.440317                             -0.278915               -0.152772        -0.0383629           -0.815954                -0.404837                -0.34972                       -0.63773                                         -0.831441       0.143393     0.38704      1.32922     \n",
            "\n",
            "  71                        -0.00931887                           -0.24418                 0.204443        -0.521502             0.259541                 0.14586                  0.203256                       1.33053                                          1.20317        0.143393    -0.93936      0.581913    \n",
            "\n",
            "  72                        -0.871314                              1.71836                 0.618813         1.90252             -0.0515527                0.14586                 -0.34972                       -0.174609                                        -0.0175966     -0.503626     0.177608     0.415845    \n",
            "\n",
            "  73                         1.71467                              -1.26887                 1.09034          0.636365             0.757291                 0.696558                 0.756232                       0.983194                                         1.61009        0.790413     1.71344     -0.663601    \n",
            "\n",
            "  74                        -1.30231                              -0.0531356              -0.931502        -0.363232            -0.691517                 0.696558                 0.756232                      -0.000938759                                     -1.35463        0.790413    -0.636848    -0.912704    \n",
            "\n",
            "  75                         0.421679                             -0.574165                0.168722        -1.17957             -0.478196                 0.14586                  0.203256                      -0.40617                                          0.389326       0.143393     0.41031     -0.456015    \n",
            "\n",
            "  76                        -0.871314                              0.0510702              -1.28872         -1.69603             -0.913727                 0.696558                 0.756232                      -0.63773                                         -1.41276        1.43743     -1.19533     -1.6185      \n",
            "\n",
            "  77                        -0.440317                              1.28417                 0.125856         0.478096             1.28171                  0.14586                  0.203256                       4.51449                                         -0.250124       0.143393    -0.96263      0.540396    \n",
            "\n",
            "  78                        -0.440317                              1.14523                -0.288514        -0.396552            -0.327093                 0.14586                  0.203256                       0.0569514                                       -0.366387       0.143393    -0.613578     0.664947    \n",
            "\n",
            "  79                        -0.440317                             -0.296283                0.847431         0.478096            -0.12266                  0.14586                  0.203256                      -0.869291                                         0.85438        0.143393     1.64363     -0.912704    \n",
            "\n",
            "  80                        -0.440317                             -0.90415                -0.717173        -0.338242            -0.718182                -0.955535                -0.902696                      -0.63773                                         -0.947705      -1.15065     -0.96263      1.41226     \n",
            "\n",
            "  81                        -0.00931887                            0.120541               -1.07439         -0.929671            -1.34926                  0.14586                  0.203256                      -1.3903                                          -1.06397        0.143393    -0.729929     0.0421904   \n",
            "\n",
            "  82                         0.852677                              2.43044                 3.67658          2.54393              2.16166                  0.14586                  0.203256                       3.99348                                          2.07515        0.143393     0.50339      1.49529     \n",
            "\n",
            "  83                         0.421679                             -0.886782               -0.395679        -0.613131             0.881729                 0.14586                  0.203256                       1.33053                                          0.0405351      0.143393    -0.357606    -0.165395    \n",
            "\n",
            "  84                        -0.440317                              1.2147                  0.225876         0.836285            -0.433754                 0.14586                  0.203256                      -0.40617                                         -0.366387       0.143393     1.24804      0.291293    \n",
            "\n",
            "  85                        -0.440317                              2.01361                 0.661679        -0.513172             0.330648                 0.14586                  0.203256                       0.693743                                         1.90075        0.143393    -0.613578     0.249776    \n",
            "\n",
            "  86                        -0.871314                             -0.643635               -0.395679        -0.596471            -0.282651                -0.404837                -0.34972                       -0.174609                                        -0.366387      -0.503626     0.549931     0.166742    \n",
            "\n",
            "  87                        -0.440317                             -0.348385               -0.474266         0.144897            -0.149325                 0.14586                  0.203256                      -0.46406                                         -0.13386        0.143393     0.131068    -1.16181     \n",
            "\n",
            "  88                        -0.440317                             -1.12993                -0.588575        -0.146653            -0.869285                 0.14586                  0.203256                      -0.927181                                        -0.889573       0.143393     0.945524    -1.28636     \n",
            "\n",
            "  89                        -0.871314                             -0.6089                 -0.495699        -0.371562            -0.67374                  0.696558                -0.34972                       -0.57984                                         -0.831441      -0.503626     0.131068    -0.0408439   \n",
            "\n",
            "  90                         0.421679                             -0.0357679              -0.238504         0.819625             0.15288                  0.696558                 0.756232                       0.751633                                         0.505589       0.790413    -0.380876    -0.372981    \n",
            "\n",
            "  91                         1.28367                               1.44048                -0.124195        -0.688101             0.0373312                0.14586                  0.203256                      -0.116719                                        -0.0757284      0.143393    -0.171445     1.32922     \n",
            "\n",
            "  92                        -0.00931887                            2.53464                 2.59064          0.236526             1.71724                  0.14586                  0.203256                       3.76192                                          0.621853       0.143393     0.898983     2.61625     \n",
            "\n",
            "  93                        -0.440317                              0.780511               -0.688596        -0.454862            -0.504861                 0.14586                 -0.34972                        0.114842                                        -0.657046      -0.503626    -0.660118     0.249776    \n",
            "\n",
            "  94                        -0.440317                             -0.97362                -0.952935        -1.1879              -0.513749                 0.14586                  0.203256                      -0.116719                                        -1.23836        0.143393    -0.89282     -1.36939     \n",
            "\n",
            "  95                        -0.440317                             -0.817312               -0.931502        -0.271602            -0.691517                 0.14586                  0.203256                      -0.753511                                        -0.250124       0.143393    -0.567037    -1.36939     \n",
            "\n",
            "  96                        -0.00931887                            1.1105                  1.20465         -0.363232             0.268429                -0.404837                -0.34972                        0.404292                                         2.13328       -0.503626     0.736092     0.581913    \n",
            "\n",
            "  97                        -0.871314                              0.0858055               1.56901         -0.962991            -0.780401                 0.696558                 0.756232                      -0.927181                                         2.59833        0.790413     3.17946      0.457362    \n",
            "\n",
            "  98                         3.43866                              -0.90415                 0.468783         0.169887             0.499528                 0.14586                  0.203256                       1.67788                                          1.14504        0.143393    -0.311066     0.581913    \n",
            "\n",
            "  99                        -0.00931887                            1.05839                -0.517132         0.286506            -0.780401                 0.14586                  0.203256                      -0.63773                                          0.85438        0.143393    -0.334336     0.249776    \n",
            "\n",
            " 100                         0.421679                              0.93682                -0.167061         0.136567            -0.104883                 0.14586                  0.203256                      -0.232499                                        -0.598914       0.143393    -0.520497     0.457362    \n",
            "\n",
            " 101                        -0.871314                              0.172644                2.29773          1.61097              7.5658                   0.14586                  0.203256                       1.44632                                          0.156799       0.143393    -0.101634     1.45377     \n",
            "\n",
            " 102                        -0.440317                             -0.0184003              -0.524276         0.428116            -0.371535                 0.14586                  0.203256                      -0.0588289                                        1.4357         0.143393    -1.10225      0.33281     \n",
            "\n",
            " 103                        -0.440317                             -0.122606                0.161577         0.386466            -0.12266                  0.14586                  0.203256                      -0.116719                                         0.156799       0.143393    -0.00855336  -0.53905     \n",
            "\n",
            " 104                        -0.871314                             -0.747841               -0.495699        -0.271602            -0.67374                  0.696558                 0.756232                      -0.63773                                         -0.889573       0.790413     0.0612572    0.166742    \n",
            "\n",
            " 105                        -0.00931887                           -0.226812                1.22608          1.99415              0.472862                 0.14586                  0.203256                      -0.46406                                          1.49383        0.143393     0.293959    -0.663601    \n",
            "\n",
            " 106                         1.28367                              -0.417856                0.304463         1.2028              -0.247097                 0.14586                  0.203256                      -0.000938759                                      1.2613         0.143393     0.43358     -0.53905     \n",
            "\n",
            " 107                         1.28367                              -0.0705032               0.161577        -0.313252             1.15727                  0.14586                  0.203256                       1.27264                                          0.970643       0.143393    -0.520497    -0.206912    \n",
            "\n",
            " 108                         0.852677                              1.30154                 0.218732        -0.00504301           0.0195545                0.14586                  0.203256                      -0.34828                                         -0.657046       0.143393    -0.357606     0.706465    \n",
            "\n",
            " 109                        -0.871314                             -0.122606               -0.602864        -1.29619             -0.327093                 0.14586                  0.203256                      -0.927181                                        -0.947705       0.143393    -0.89282     -0.456015    \n",
            "\n",
            " 110                        -0.871314                             -2.05041                -0.724317        -1.16291             -0.0693295                0.14586                  0.203256                      -0.000938759                                     -1.2965         0.790413    -0.823009    -0.995738    \n",
            "\n",
            " 111                         0.421679                             -1.32097                 0.354474         0.777975             0.055108                 0.696558                 0.756232                       0.0569514                                       -0.773309       0.790413     0.154338    -0.414498    \n",
            "\n",
            " 112                         0.421679                              1.00629                 0.218732         0.653025            -0.833731                -0.404837                -0.34972                       -0.985071                                        -0.250124      -0.503626     1.29458      2.45018     \n",
            "\n",
            " 113                        -0.871314                              1.42311                 0.704545         1.58598             -0.0871062                0.14586                  0.203256                       0.577963                                        -0.715178       0.143393     0.712822     2.4917      \n",
            "\n",
            " 114                        -0.440317                             -0.487327                0.940307         1.29443              0.748403                 0.696558                 0.203256                      -0.46406                                         -0.657046       0.143393     0.619741     0.166742    \n",
            "\n",
            " 115                        -0.00931887                            0.745776               -0.417112         0.503086            -0.638187                 0.14586                  0.203256                      -1.04296                                         -0.250124       0.143393     0.0612572    0.415845    \n",
            "\n",
            " 116                        -0.440317                              0.259482                0.0972785        0.669685            -0.131548                 0.14586                  0.203256                       0.114842                                         0.796248       0.143393     0.177608     0.208259    \n",
            "\n",
            " 117                        -0.00931887                           -0.435224               -0.295659        -0.438202            -0.362646                 0.14586                  0.203256                      -0.174609                                         0.912511       0.143393    -0.683388    -0.331464    \n",
            "\n",
            " 118                        -1.30231                               0.190011                0.040124         0.877935             0.455086                 0.14586                  0.203256                       1.27264                                         -1.1221         0.143393     0.549931     1.08012     \n",
            "\n",
            " 119                        -0.00931887                           -0.417856               -1.30301         -0.954661            -0.807066                 0.14586                  0.203256                      -0.40617                                         -0.947705       0.143393    -1.24187     -0.871187    \n",
            "\n",
            " 120                         2.14567                               1.8052                  1.33324          1.54433             -0.327093                 0.14586                  0.203256                      -0.0588289                                        2.19141        0.143393     3.226        0.415845    \n",
            "\n",
            " 121                         0.421679                              0.0510702              -0.152772         0.236526            -0.824843                 0.14586                  0.203256                      -0.985071                                         0.389326       0.143393     0.224148     0.125225    \n",
            "\n",
            " 122                        -0.440317                             -1.40781                -0.717173         0.0449369            0.215099                 0.14586                  0.203256                      -0.34828                                          0.389326       0.143393    -1.10225     -0.746635    \n",
            "\n",
            " 123                        -1.73331                              -2.3804                 -2.08888         -1.83764             -1.32259                 -3.70902                 -3.66758                       -1.27452                                         -1.93594       -3.0917      -1.82363     -1.70153     \n",
            "\n",
            " 124                        -0.871314                              0.502629               -0.524276        -0.579812             0.09955                 -0.404837                -0.34972                        1.38842                                         -1.1221        -0.503626    -0.660118    -0.871187    \n",
            "\n",
            " 125                        -0.440317                             -0.661003                0.290175        -0.938001            -0.389312                 0.696558                 0.203256                      -0.695621                                        -1.00584        0.143393     2.66752     -1.24484     \n",
            "\n",
            " 126                        -0.440317                             -0.765209               -1.01009         -0.313252            -0.691517                 0.14586                 -0.34972                       -0.753511                                        -0.831441       0.143393    -1.00917     -0.53905     \n",
            "\n",
            " 127                        -0.440317                             -0.296283               -1.14583         -0.521502            -0.513749                 0.14586                 -0.34972                       -0.811401                                        -0.773309      -0.503626    -0.91609     -1.28636     \n",
            "\n",
            " 128                         0.421679                              0.103173               -0.481411        -0.179973             0.143992                -0.404837                -0.34972                        2.37256                                         -0.657046      -0.503626    -0.520497    -0.0408439   \n",
            "\n",
            " 129                         0.852677                              1.33628                -0.0241748        0.669685             0.241764                 0.14586                  0.203256                       1.04108                                          2.01701        0.143393    -1.12552      2.07653     \n",
            "\n",
            " 130                         2.57667                              -0.0531356               1.33324          1.16948             -0.273762                 0.696558                 0.756232                      -0.174609                                         0.621853       0.790413     1.71344      1.41226     \n",
            "\n",
            " 131                        -0.871314                             -0.452591               -0.0313191        0.103247             0.0817732               -0.404837                -0.34972                        0.925304                                        -0.424519      -0.503626    -0.590308    -0.497532    \n",
            "\n",
            " 132                         2.57667                               0.120541               -0.23136          0.169887             0.206211                 0.14586                  0.203256                       1.67788                                          1.4357         0.143393    -0.985901    -0.871187    \n",
            "\n",
            " 133                         0.421679                             -0.97362                -0.781472        -0.546492            -0.878173                 0.14586                  0.203256                      -0.57984                                         -0.889573       0.143393     0.270689    -1.57698     \n",
            "\n",
            " 134                        -0.871314                              0.0510702               1.07605         -0.213292             0.997278                 0.14586                  0.203256                       1.27264                                          0.389326       0.143393     1.15496      1.32922     \n",
            "\n",
            " 135                        -0.871314                              0.259482                0.633102         0.0865868            1.20171                  0.14586                  0.203256                       0.577963                                         1.20317        0.143393     0.224148     0.457362    \n",
            "\n",
            " 136                         0.421679                             -0.192077               -0.109907        -0.729751             0.499528                 0.696558                 0.756232                      -0.116719                                         0.796248       1.43743     -0.636848    -1.24484     \n",
            "\n",
            " 137                         2.57667                              -1.00836                -0.545709        -0.254942            -0.84262                 -2.05693                 -2.00865                       -1.10085                                          1.2613        -2.44468      0.270689    -0.82967     \n",
            "\n",
            " 138                         0.421679                             -0.574165               -1.02438         -0.629791            -0.202655                 0.14586                  0.203256                      -0.811401                                        -0.366387       0.143393    -1.19533     -1.24484     \n",
            "\n",
            " 139                        -0.440317                             -0.400488                0.261598        -0.496512             0.721737                 0.14586                  0.203256                       0.751633                                        -0.889573       0.143393    -0.357606     0.706465    \n",
            "\n",
            " 140                        -0.871314                              0.172644                0.383051         0.0615968            0.312871                 0.696558                 0.756232                      -0.174609                                        -0.424519       0.790413     0.643011     0.33281     \n",
            "\n",
            " 141                         1.71467                               0.0858055               0.283031        -0.329912             0.0639964                0.696558                 0.756232                      -0.000938759                                      1.55196        0.790413    -0.0783639    0.457362    \n",
            "\n",
            " 142                        -0.871314                             -0.695738               -1.09582         -1.01297             -0.753736                 0.14586                  0.203256                      -0.46406                                         -0.715178       0.143393    -1.24187     -0.82967     \n",
            "\n",
            " 143                        -0.00931887                            0.0337026               0.983173         1.56099              0.81951                  0.14586                  0.203256                       1.21475                                          0.156799       0.143393     0.270689     0.374328    \n",
            "\n",
            " 144                        -0.440317                              1.23207                 0.790277         0.827955            -0.0515527                0.14586                  0.203256                      -0.174609                                        -0.598914       0.143393     1.29458      1.20467     \n",
            "\n",
            " 145                        -0.00931887                           -0.24418                -0.245648        -0.754741            -0.158213                 0.14586                 -0.34972                       -0.52195                                          0.679984      -0.503626    -1.05571     -0.82967     \n",
            "\n",
            " 146                        -2.16431                              -2.17199                -2.21748         -2.11253             -1.30482                 -5.91181                 -5.87948                       -1.27452                                         -2.16847       -5.67978     -2.03306     -1.45243     \n",
            "\n",
            " 147                         1.28367                               1.8052                  0.854575         0.844615             0.410644                 0.14586                  0.203256                       0.346402                                         0.738116       0.143393    -0.241255     0.415845    \n",
            "\n",
            " 148                        -2.16431                              -2.4325                 -2.30321         -2.19583             -1.40259                 -5.91181                 -5.87948                       -1.3903                                          -2.16847       -5.67978     -2.05633     -1.74305     \n",
            "\n",
            " 149                        -0.00931887                           -0.0184003               0.675968         1.51101              0.437309                 0.14586                  0.203256                       0.809523                                         0.505589       0.143393     0.224148     1.61984     \n",
            "\n",
            " 150                        -0.871314                             -0.765209               -1.29586         -1.62939             -0.984834                -0.955535                -0.902696                      -1.15874                                         -0.598914      -1.15065     -0.473957    -1.20332     \n",
            "\n",
            " 151                        -0.440317                             -0.0705032               0.775988         0.977894             0.401755                 0.14586                 -0.34972                       -0.0588289                                        0.505589       0.143393    -0.590308    -0.580567    \n",
            "\n",
            " 152                         0.421679                              1.71836                 0.675968         0.977894             0.170657                 0.14586                  0.203256                       1.33053                                          1.78449        0.143393     0.643011     1.74439     \n",
            "\n",
            " 153                         2.57667                               1.04103                -0.638585        -0.379892            -0.167102                 0.14586                  0.203256                       0.867414                                         1.37757        0.143393    -0.729929     0.125225    \n",
            "\n",
            " 154                         0.421679                              1.23207                -0.259937        -0.179973            -0.540414                 0.14586                  0.203256                       0.0569514                                        0.156799       0.143393    -0.753199     0.125225    \n",
            "\n",
            " 155                        -0.00931887                           -0.278915               -0.588575        -0.0966728           -0.709294                 0.14586                  0.203256                      -0.63773                                         -0.191992       0.143393    -0.473957    -0.995738    \n",
            "\n",
            " 156                         0.421679                             -0.487327                1.07605         -0.688101             1.30837                  0.696558                 0.203256                       0.983194                                        -0.13386        0.143393    -0.567037     0.000673251 \n",
            "\n",
            " 157                        -0.00931887                            0.016335                1.03318          0.0615968            1.53947                  0.14586                  0.203256                       1.90944                                          0.0986669      0.143393     0.992064     1.45377     \n",
            "\n",
            " 158                        -0.00931887                            1.38838                 0.418772        -0.346572            -0.0248875                0.14586                  0.203256                      -0.985071                                         0.273062       0.143393     0.270689     1.12164     \n",
            "\n",
            " 159                        -0.00931887                           -0.00103267             -0.509988         0.119907            -0.300428                 0.14586                 -0.902696                       0.288512                                        -0.598914      -0.503626     0.340499    -0.82967     \n",
            "\n",
            " 160                        -0.871314                             -0.139974               -0.667163        -0.463192            -0.771512                 0.696558                 0.756232                      -0.63773                                         -1.47089        0.790413     0.224148    -0.705118    \n",
            "\n",
            " 161                         0.421679                             -0.00103267             -0.638585        -0.913011            -0.353758                 0.14586                 -0.34972                       -0.116719                                        -0.191992      -0.503626    -0.497227    -0.0408439   \n",
            "\n",
            " 162                        -0.00931887                            1.63153                 1.16178          1.21113              0.890617                 0.14586                  0.203256                       0.983194                                         1.20317        0.143393     0.0612572    1.20467     \n",
            "\n",
            " 163                        -0.440317                              1.07576                -0.0456077       -0.679771            -0.567079                -0.404837                -0.34972                       -0.695621                                        -0.482651      -0.503626     1.52728      0.33281     \n",
            "\n",
            " 164                        -0.871314                             -0.0705032              -1.11011         -1.15458             -0.549303                 0.14586                  0.203256                      -0.63773                                         -1.70342        0.143393    -1.03244     -0.622084    \n",
            "\n",
            " 165                        -0.00931887                            1.52732                 0.968884         0.0865868            0.437309                -1.50623                 -1.45567                       -0.40617                                          1.49383       -1.79766      0.526661     1.66136     \n",
            "\n",
            " 166                        -0.00931887                            0.120541                0.661679         1.42771              1.43281                  0.696558                 0.756232                       2.08311                                          0.156799       0.790413     0.782632    -0.622084    \n",
            "\n",
            " 167                        -0.440317                              0.867349               -0.0884736        1.1195              -0.0693295                0.14586                  0.203256                      -0.232499                                        -1.00584        0.143393     0.363769     0.581913    \n",
            "\n",
            " 168                        -0.871314                              0.120541                1.03318         -0.021703             0.632854                 0.14586                  0.203256                       1.50421                                         -0.657046       0.143393    -0.311066     1.0386      \n",
            "\n",
            " 169                        -0.440317                              0.780511                0.154433         0.0699268           -0.273762                 0.14586                  0.203256                      -0.116719                                        -0.250124       0.143393    -0.241255     0.374328    \n",
            "\n",
            " 170                         0.421679                              0.0337026               0.283031        -0.962991             0.863952                 0.696558                 0.756232                       0.172732                                         0.0405351      0.790413     0.922254     0.706465    \n",
            "\n",
            " 171                         1.28367                               1.33628                 0.747411         0.969564             0.312871                 0.14586                  0.203256                      -0.52195                                          1.66822        0.143393    -0.194715     0.457362    \n",
            "\n",
            " 172                         1.71467                              -0.331018                0.668823        -0.105003             0.712849                 0.14586                  0.203256                       0.635853                                         1.31943        0.143393     0.50339      0.91405     \n",
            "\n",
            " 173                         0.421679                             -1.72043                -0.945791        -1.3545              -0.860396                -0.404837                -0.34972                       -0.753511                                        -0.773309      -0.503626     0.340499    -1.36939     \n",
            "\n",
            " 174                        -0.440317                              0.0510702              -0.102762        -0.604801            -0.940392                 0.696558                 0.756232                      -1.04296                                         -0.598914       0.790413    -0.334336    -1.70153     \n",
            "\n",
            " 175                        -0.871314                             -2.13725                -0.752894        -0.413212             0.472862                 0.696558                 0.203256                      -0.232499                                        -1.18023        0.790413    -0.93936     -0.995738    \n",
            "\n",
            " 176                        -0.00931887                            1.45785                -0.424256         0.236526            -0.664852                 0.14586                  0.203256                      -0.753511                                        -0.540782       0.143393    -0.753199     1.37074     \n",
            "\n",
            " 177                        -0.440317                             -1.44255                -0.474266        -1.07128             -0.380423                 0.696558                 0.756232                       0.404292                                        -1.23836        0.790413     0.154338     0.125225    \n",
            "\n",
            " 178                        -0.00931887                           -1.1994                 -0.28137         -0.329912             0.295095                 0.696558                 0.756232                      -0.29039                                          0.156799       0.790413     0.736092    -1.20332     \n",
            "\n",
            " 179                        -0.00931887                           -0.174709                0.125856         0.569726             0.00177768              -0.404837                -0.34972                        0.114842                                         0.912511      -0.503626     0.666282    -0.788152    \n",
            "\n",
            " 180                         4.30066                              -0.226812               -0.717173        -0.98798             -0.442642                -0.404837                -0.34972                       -0.174609                                         0.389326      -0.503626    -0.543767    -0.622084    \n",
            "\n",
            " 181                         0.852677                             -0.0878709               0.0186911       -0.346572             0.0728848                0.14586                  0.203256                       0.230622                                        -0.0757284      0.143393     0.224148     0.166742    \n",
            "\n",
            " 182                        -0.440317                             -0.417856                0.190154        -0.138323             0.552858                 0.696558                 0.756232                      -0.29039                                          0.21493        0.790413     0.666282    -0.53905     \n",
            "\n",
            " 183                        -0.440317                              0.971555               -0.109907         0.253186             0.0639964                0.14586                  0.203256                      -0.811401                                         0.0986669      0.143393     0.689552     0.789499    \n",
            "\n",
            " 184                        -0.440317                             -1.7899                 -0.902925        -0.554822            -0.220432                 0.696558                 0.756232                      -0.29039                                         -0.831441       1.43743     -1.14879     -0.24843     \n",
            "\n",
            " 185                        -0.382239                             -1.28291                -0.911639        -0.296946            -0.361323                -0.330629                -0.275205                      -0.992872                                        -0.250124       0.143393    -0.301163    -0.589988    \n",
            "\n",
            " 186                        -2.05227                              -2.13587                -2.1079          -1.95878             -1.30251                 -5.76866                 -5.73573                       -1.30462                                         -2.0778        -5.51158     -1.83948     -1.32292     \n",
            "\n",
            " 187                        -1.44675                              -1.57115                -1.56677         -1.18464             -1.1866                  -4.44575                 -4.40735                       -1.33257                                         -1.55879       -4.17239     -1.06407     -0.726491    \n",
            "\n",
            " 188                        -0.555099                             -1.6374                 -1.06032         -0.519153            -0.405                   -0.84482                 -0.791523                      -1.02104                                         -0.389458      -0.316109    -0.440236    -0.765063    \n",
            "\n",
            " 189                        -1.87023                              -1.39718                -1.77676         -1.56153             -1.20287                 -4.97242                 -4.9362                        -1.32118                                         -1.69659       -4.68645     -1.18754     -1.36647     \n",
            "\n",
            " 190                        -0.807988                             -1.77665                -1.26901         -0.79994             -0.549469                -1.5793                  -1.52904                       -1.07149                                         -0.659245      -1.0985      -0.719889    -0.959138    \n",
            "\n",
            " 191                        -2.16431                              -2.35128                -2.27648         -2.16986             -1.37211                 -5.91181                 -5.87948                       -1.3542                                          -2.16847       -5.67978     -2.04907     -1.65244     \n",
            "\n",
            " 192                        -2.16431                              -2.06647                -2.17935         -2.05991             -1.39655                 -5.91181                 -5.87948                       -1.3903                                          -2.10919       -5.67978     -1.81902     -1.65837     \n",
            "\n",
            " 193                        -1.97271                              -2.40934                -2.20793         -2.0366              -1.36703                 -4.93258                 -4.8962                        -1.33883                                         -2.0651        -4.52927     -1.95288     -1.72459     \n",
            "\n",
            " 194                        -1.73331                              -2.16029                -1.90327         -1.63706             -1.3057                  -4.75589                 -4.71878                       -1.34789                                         -1.86227       -4.32168     -1.48448     -1.22799     \n",
            "\n",
            " 195                        -2.09555                              -1.46377                -1.91605         -1.75213             -1.37063                 -5.82396                 -5.79126                       -1.3903                                          -1.96625       -5.57656     -1.34709     -1.40784     \n",
            "\n",
            " 196                        -0.150825                             -0.0240185              -0.604763         0.19951             -0.533129                -0.0349458                0.0217018                     -1.02395                                         -0.250124       0.143393    -0.0762649    0.0341768   \n",
            "\n",
            " 197                        -0.148348                             -0.0105436              -0.601478         0.204824            -0.534968                -0.0317808                0.0248798                     -1.02429                                         -0.250124       0.143393    -0.0738576    0.0408577   \n",
            "\n",
            " 198                        -2.05275                              -1.37144                -1.87736         -1.70705             -1.31579                 -5.55546                 -5.52165                       -1.36408                                         -1.88123       -5.30297     -1.29347     -1.44559     \n",
            "\n",
            " 199                        -1.7678                               -2.38457                -2.10603         -1.8663              -1.32899                 -3.88527                 -3.84456                       -1.28379                                         -1.95455       -3.29878     -1.84225     -1.70485     \n",
            "\n",
            " 200                        -1.74681                              -2.38203                -2.09559         -1.84886             -1.3251                  -3.77803                 -3.73687                       -1.27815                                         -1.94323       -3.17278     -1.83092     -1.70283     \n",
            "\n",
            " 201                        -2.08136                              -2.35563                -2.20559         -2.06598             -1.38206                 -5.80583                 -5.77306                       -1.3903                                          -2.10135       -5.55526     -1.90854     -1.59124     \n",
            "\n",
            " 202                        -2.16431                              -2.19463                -2.22493         -2.11977             -1.31331                 -5.91181                 -5.87948                       -1.28459                                         -2.16847       -5.67978     -2.03508     -1.47769     \n",
            "\n",
            " 203                        -0.557863                             -1.63833                -1.06205         -0.521503            -0.40709                 -0.855415                -0.802162                      -1.02191                                         -0.392813      -0.327174    -0.442226    -0.765507    \n",
            "\n",
            " 204                        -1.97341                              -2.25558                -2.07854         -1.89698             -1.35535                 -5.6679                  -5.63456                       -1.3903                                          -2.01399       -5.3932      -1.7162      -1.39366     \n",
            "\n",
            " 205                        -1.48537                              -1.63341                -1.59766         -1.22999             -1.20133                 -4.56912                 -4.53123                       -1.34035                                         -1.59395       -4.28835     -1.09431     -0.757183    \n",
            "\n",
            " 206                        -1.78322                              -2.04914                -1.84478         -1.58959             -1.29696                 -5.42489                 -5.39054                       -1.37689                                         -1.86007       -5.10769     -1.37464     -1.01191     \n",
            "\n",
            " 207                        -1.88983                              -2.30471                -2.13558         -1.93746             -1.31614                 -4.50897                 -4.47083                       -1.27452                                         -2.02039       -4.03157     -1.89968     -1.61107     \n",
            "\n",
            " 208                        -1.75236                              -2.03919                -1.81459         -1.54724             -1.29632                 -5.38545                 -5.35094                       -1.38519                                         -1.8351        -5.06136     -1.32132     -0.976239    \n",
            "\n",
            " 209                        -1.79877                              -2.22476                -2.06609         -1.83131             -1.33204                 -4.0436                  -4.00353                       -1.29211                                         -1.94477       -3.48479     -1.75294     -1.67        \n",
            "\n",
            " 210                        -1.73331                              -2.11001                -1.86087         -1.59124             -1.30184                 -4.99504                 -4.95892                       -1.36465                                         -1.84544       -4.60266     -1.40701     -1.11981     \n",
            "\n",
            " 211                         0.278374                              1.07038                -0.436187         0.169468            -1.05943                  0.14586                  0.203256                      -1.23617                                          0.370728       0.575282     0.0923231    0.443558    \n",
            "\n",
            " 212                        -1.72158                              -2.0248                 -1.90191         -1.67827             -1.05145                 -4.4976                  -4.45941                       -1.20019                                         -1.67583       -4.18436     -1.60279     -1.27118     \n",
            "\n",
            " 213                        -2.16431                              -1.91714                -2.13049         -2.0137              -1.32979                 -5.91181                 -5.87948                       -1.31067                                         -2.11402       -5.67978     -1.82237     -1.46539     \n",
            "\n",
            " 214                         0.16643                               0.804189               -0.640318        -0.214762            -1.27558                 -0.310733                -0.255227                      -1.32556                                          0.370139       0.330594    -0.120971     0.201651    \n",
            "\n",
            " 215                        -0.387175                             -0.123835               -1.06244         -0.687686            -1.28928                 -1.30103                 -1.24962                       -1.31068                                         -0.301879      -0.666701    -0.617144    -0.352957    \n",
            "\n",
            " 216                        -1.73331                              -2.37006                -2.08016         -1.82821             -1.3218                  -3.75821                 -3.71697                       -1.27797                                         -1.93248       -3.1495      -1.80769     -1.67928     \n",
            "\n",
            " 217                        -1.36745                              -1.4681                 -1.49965         -1.16069             -0.891806                -3.36639                 -3.32352                       -1.203                                           -1.18799       -2.9882      -0.89572     -1.14852     \n",
            "\n",
            " 218                        -1.75666                              -1.99635                -1.8037          -1.53599             -1.30074                 -5.39095                 -5.35646                       -1.3903                                          -1.82913       -5.06781     -1.29219     -0.983459    \n",
            "\n",
            " 219                        -0.776711                             -0.491148               -1.03087         -0.39793             -0.930964                -2.30543                 -2.25818                       -1.19757                                         -0.948773      -2.16064     -0.539515    -0.194006    \n",
            "\n",
            " 220                        -2.16431                              -2.33459                -2.27099         -2.16452             -1.36584                 -5.91181                 -5.87948                       -1.34679                                         -2.16847       -5.67978     -2.04758     -1.63382     \n",
            "\n",
            " 221                        -1.06408                              -1.16686                -1.43992         -0.928998            -1.05691                 -2.21261                 -2.16497                       -1.18463                                         -1.28153       -1.83588     -1.09194     -0.879591    \n",
            "\n",
            " 222                        -1.73331                              -2.35726                -2.06937         -1.81655             -1.32082                 -3.81909                 -3.77809                       -1.28224                                         -1.9282        -3.22102     -1.78797     -1.65174     \n",
            "\n",
            " 223                        -2.16431                              -2.14663                -2.20648         -2.08968             -1.39787                 -5.91181                 -5.87948                       -1.3903                                          -2.12217       -5.67978     -1.87099     -1.67691     \n",
            "\n",
            " 224                        -1.4313                               -1.54625                -1.55442         -1.1665              -1.18071                 -4.39641                 -4.35781                       -1.32946                                         -1.54473       -4.12601     -1.05198     -0.714214    \n",
            "\n",
            " 225                        -0.150816                             -0.648091               -0.806301        -0.278863            -0.637617                -0.219886                -0.164003                      -1.10173                                          0.0622526      0.360695    -0.2013      -0.342274    \n",
            "\n",
            " 226                        -0.599847                             -1.676                  -1.1103          -0.585726            -0.418548                -0.914427                -0.861418                      -1.02257                                         -0.427639      -0.395456    -0.514798    -0.838839    \n",
            "\n",
            " 227                        -0.679791                             -1.7436                 -1.19243         -0.683816            -0.504226                -1.0168                  -0.964217                      -1.03868                                         -0.562353      -0.455776    -0.629127    -0.92349     \n",
            "\n",
            " 228                        -1.14367                              -1.49966                -1.37632         -0.982292            -0.753361                -2.65159                 -2.60576                       -1.1504                                          -0.961625      -2.23236     -0.76584     -1.05152     \n",
            "\n",
            " 229                        -1.16752                              -1.1758                 -1.44145         -1.12087             -1.28893                 -3.91527                 -3.87468                       -1.3751                                          -1.1634        -3.5039      -0.921841    -0.583613    \n",
            "\n",
            " 230                        -0.153038                             -0.0360564              -0.607697         0.194763            -0.531487                -0.0377732                0.0188627                     -1.02366                                         -0.250124       0.143393    -0.0784154    0.0282083   \n",
            "\n",
            " 231                        -2.16431                              -2.40284                -2.29345         -2.18634             -1.39146                 -5.91181                 -5.87948                       -1.37712                                         -2.16847       -5.67978     -2.05368     -1.70995     \n",
            "\n",
            " 232                         0.0507381                             0.813538               -0.421094         0.433442            -0.726123                 0.14586                  0.203256                      -1.08329                                         -0.120519       0.233552     0.0677423    0.42163     \n",
            "\n",
            " 233                        -2.16431                              -2.2547                 -2.24305         -2.12981             -1.39965                 -5.91181                 -5.87948                       -1.3903                                          -2.13968       -5.67978     -1.94106     -1.70192     \n",
            "\n",
            " 234                        -1.83276                              -2.39242                -2.13834         -1.92029             -1.34105                 -4.21731                 -4.17796                       -1.30124                                         -1.9896        -3.68889     -1.87732     -1.71111     \n",
            "\n",
            " 235                        -0.508115                             -1.62162                -1.03099         -0.479197            -0.369471                -0.664719                -0.610677                      -1.00632                                         -0.332423      -0.128018    -0.406413    -0.75752     \n",
            "\n",
            " 236                        -1.7942                               -2.08948                -1.86763         -1.61642             -1.311                   -5.43892                 -5.40463                       -1.3903                                          -1.86896       -5.12417     -1.3969      -1.06567     \n",
            "\n",
            " 237                        -0.878932                             -1.74614                -1.26252         -0.794539            -0.649873                -2.08613                 -2.03797                       -1.12254                                         -0.782557      -1.61249     -0.673359    -0.817053    \n",
            "\n",
            " 238                        -1.48635                              -2.10467                -1.78627         -1.4981              -0.976158                -3.74621                 -3.70492                       -1.23095                                         -1.41409       -3.38984     -1.38831     -1.35121     \n",
            "\n",
            " 239                        -2.04778                              -2.13442                -2.10351         -1.95263             -1.30241                 -5.76292                 -5.72997                       -1.30583                                         -2.07417       -5.50485     -1.83173     -1.31773     \n",
            "\n",
            " 240                        -2.16431                              -2.20409                -2.22804         -2.12279             -1.31686                 -5.91181                 -5.87948                       -1.28879                                         -2.16847       -5.67978     -2.03593     -1.48824     \n",
            "\n",
            " 241                        -1.14249                              -1.83465                -1.42707         -1.01867             -0.849168                -3.0964                  -3.05242                       -1.20514                                         -1.10249       -2.66757     -0.863091    -0.859367    \n",
            "\n",
            " 242                        -2.16431                              -1.60845                -2.02437         -1.88984             -1.38898                 -5.91181                 -5.87948                       -1.3903                                          -2.03501       -5.67978     -1.52208     -1.55241     \n",
            "\n",
            " 243                        -1.16847                              -1.84337                -1.44329         -1.04076             -0.868812                -3.19598                 -3.15241                       -1.21328                                         -1.13402       -2.77157     -0.881793    -0.863538    \n",
            "\n",
            " 244                        -2.16431                              -2.21417                -2.22933         -2.11475             -1.39898                 -5.91181                 -5.87948                       -1.3903                                          -2.13311       -5.67978     -1.91478     -1.69254     \n",
            "\n",
            " 245                        -2.16431                              -1.75455                -2.07499         -1.95065             -1.34572                 -5.91181                 -5.87948                       -1.33373                                         -2.07929       -5.67978     -1.68796     -1.47366     \n",
            "\n",
            " 246                        -1.62195                              -2.19373                -2.00397         -1.74251             -1.31984                 -3.50983                 -3.46755                       -1.27751                                         -1.80077       -2.8911      -1.72382     -1.58997     \n",
            "\n",
            " 247                        -1.52327                              -1.44612                -1.58554         -1.28492             -0.988211                -3.86413                 -3.82333                       -1.23962                                         -1.34562       -3.51453     -0.98616     -1.21607     \n",
            "\n",
            " 248                        -2.08538                              -1.36684                -1.89535         -1.73306             -1.33598                 -5.6597                  -5.62632                       -1.37175                                         -1.91424       -5.41319     -1.31241     -1.45973     \n",
            "\n",
            " 249                        -1.65934                              -2.00821                -1.74978         -1.4582              -1.24                    -5.07759                 -5.0418                        -1.36712                                         -1.72989       -4.73665     -1.23517     -0.942346    \n",
            "\n",
            " 250                        -1.73331                              -2.22368                -1.95672         -1.69482             -1.31056                 -4.45444                 -4.41608                       -1.32676                                         -1.88349       -3.9675      -1.58214     -1.36435     \n",
            "\n",
            " 251                        -0.957776                             -1.77262                -1.31174         -0.861587            -0.709492                -2.38835                 -2.34144                       -1.14725                                         -0.878264      -1.92812     -0.730117    -0.829712    \n",
            "\n",
            " 252                        -0.506254                             -1.63074                -1.03893         -0.489402            -0.359679                -0.615461                -0.561215                      -1.00057                                         -0.323494      -0.0793236   -0.422576    -0.784745    \n",
            "\n",
            " 253                         0.357189                              1.02027                -0.486311        -0.0284966           -1.19811                  0.10466                  0.161885                      -1.30643                                          0.610399       0.742006     0.0729784    0.367285    \n",
            "\n",
            " 254                        -1.94411                              -2.101                  -2.00212         -1.81036             -1.30027                 -5.63046                 -5.59696                       -1.33368                                         -1.99027       -5.34921     -1.65261     -1.19789     \n",
            "\n",
            " 255                        -1.73331                              -2.29686                -2.01843         -1.76151             -1.31618                 -4.10637                 -4.06657                       -1.30237                                         -1.90798       -3.55855     -1.6949      -1.52179     \n",
            "\n",
            " 256                        -1.69177                              -2.30507                -2.0486          -1.78124             -1.3061                  -3.61614                 -3.57431                       -1.26894                                         -1.89533       -3.01375     -1.77821     -1.65051     \n",
            "\n",
            " 257                        -1.16547                              -1.42851                -1.6559          -1.35255             -1.30854                 -2.69326                 -2.64761                       -1.28978                                         -1.24665       -2.06877     -1.3147      -1.13266     \n",
            "\n",
            " 258                        -2.14446                              -2.4301                 -2.29334         -2.17933             -1.39891                 -5.81039                 -5.77763                       -1.38497                                         -2.15777       -5.56061     -2.04561     -1.74113     \n",
            "\n",
            " 259                        -1.75965                              -2.36766                -2.09674         -1.85444             -1.32151                 -3.84363                 -3.80274                       -1.27452                                         -1.95015       -3.24985     -1.83642     -1.68631     \n",
            "\n",
            " 260                        -0.839881                             -0.760313               -1.22251         -0.624598            -0.967911                -1.7113                  -1.66158                       -1.15452                                         -1.0623        -1.41517     -0.846818    -0.604237    \n",
            "\n",
            " 261                         0.137266                              0.911167               -0.426831         0.333101            -0.852819                 0.14586                  0.203256                      -1.14141                                          0.0662115      0.363448     0.0770858    0.429965    \n",
            "\n",
            " 262                        -2.08679                              -1.54                   -1.96583         -1.80348             -1.37362                 -5.51564                 -5.48167                       -1.36948                                         -1.98362       -5.21432     -1.44193     -1.53128     \n",
            "\n",
            " 263                        -1.92167                              -1.73703                -1.85841         -1.64123             -1.33477                 -5.60178                 -5.56817                       -1.3903                                          -1.8959        -5.31552     -1.31892     -1.19009     \n",
            "\n",
            " 264                        -2.16431                              -2.06271                -2.18018         -2.07015             -1.31553                 -5.91181                 -5.87948                       -1.29002                                         -2.14512       -5.67978     -1.94271     -1.45798     \n",
            "\n",
            " 265                        -1.18667                              -2.04999                -1.62374         -1.23896             -0.89797                 -2.31212                 -2.26489                       -1.15215                                         -1.22323       -1.72401     -1.20384     -1.29783     \n",
            "\n",
            " 266                        -2.04386                              -2.41794                -2.24331         -2.09573             -1.38023                 -5.29624                 -5.26135                       -1.35795                                         -2.10349       -4.95653     -1.9913      -1.73144     \n",
            "\n",
            " 267                         0.368757                              1.17236                -0.44218          0.0646569           -1.19177                  0.14586                  0.203256                      -1.29687                                          0.565777       0.710966     0.102083     0.452264    \n",
            "\n",
            " 268                        -1.83324                              -1.876                  -1.82909         -1.58483             -1.31654                 -5.4888                  -5.45471                       -1.3903                                          -1.86012       -5.18278     -1.3046      -1.07936     \n",
            "\n",
            " 269                        -0.224805                              0.398444               -0.589458         0.250078            -0.720399                -0.542471                -0.487923                      -1.08638                                         -0.446307      -0.503587    -0.107442     0.244597    \n",
            "\n",
            " 270                        -2.06355                              -2.22071                -2.18741         -2.04826             -1.30897                 -5.39684                 -5.36238                       -1.27452                                         -2.11411       -5.07474     -1.9841      -1.51066     \n",
            "\n",
            " 271                        -2.16431                              -1.85888                -2.1106          -1.99111             -1.3355                  -5.91181                 -5.87948                       -1.31893                                         -2.10158       -5.67978     -1.77421     -1.46835     \n",
            "\n",
            " 272                        -2.16431                              -2.42133                -2.29953         -2.19225             -1.39839                 -5.91181                 -5.87948                       -1.38534                                         -2.16847       -5.67978     -2.05533     -1.73058     \n",
            "\n",
            " 273                        -2.16431                              -2.39048                -2.28938         -2.18239             -1.38682                 -5.91181                 -5.87948                       -1.37163                                         -2.16847       -5.67978     -2.05258     -1.69617     \n",
            "\n",
            " 274                        -1.90735                              -2.08915                -1.96618         -1.75992             -1.29952                 -5.58349                 -5.5498                        -1.34355                                         -1.96053       -5.29403     -1.58911     -1.1554      \n",
            "\n",
            " 275                        -1.73331                              -2.23012                -1.96216         -1.70069             -1.31106                 -4.42377                 -4.38528                       -1.32461                                         -1.88565       -3.93146     -1.59208     -1.37822     \n",
            "\n",
            " 276                        -1.10601                              -1.24289                -1.48058         -0.985928            -1.07356                 -2.30636                 -2.25911                       -1.19027                                         -1.32253       -1.91456     -1.13778     -0.931089    \n",
            "\n",
            " 277                        -2.16431                              -1.46414                -1.97586         -1.83804             -1.37418                 -5.91181                 -5.87948                       -1.37492                                         -2.01724       -5.67978     -1.44787     -1.48843     \n",
            "\n",
            " 278                         0.0263279                             0.785996               -0.419475         0.461749            -0.690381                 0.14586                  0.203256                      -1.0669                                          -0.173197       0.196907     0.0651064    0.419278    \n",
            "\n",
            " 279                         0.286749                              0.788939               -0.530681        -0.0632124           -1.12039                  0.0596585                0.116697                      -1.27804                                          0.534393       0.689133     0.0349469    0.268897    \n",
            "\n",
            " 280                        -1.7155                               -2.36963                -2.07372         -1.81813             -1.30876                 -3.66351                 -3.62187                       -1.27053                                         -1.91272       -3.04714     -1.80343     -1.68838     \n",
            "\n",
            " 281                        -2.16431                              -1.44102                -1.96797         -1.82907             -1.37645                 -5.91181                 -5.87948                       -1.3782                                          -2.0123        -5.67978     -1.42875     -1.4896      \n",
            "\n",
            " 282                        -1.43565                              -2.08016                -1.74761         -1.44592             -0.944267                -3.58426                 -3.54229                       -1.21903                                         -1.35767       -3.21858     -1.33835     -1.32191     \n",
            "\n",
            " 283                        -1.51792                              -1.98982                -1.88001         -1.54519             -1.23708                 -3.2274                  -3.18396                       -1.24559                                         -1.72532       -2.68752     -1.58813     -1.43699     \n",
            "\n",
            " 284                         0.169857                              0.94794                -0.428992         0.295307            -0.90054                  0.14586                  0.203256                      -1.16329                                          0.136545       0.412375     0.0806051    0.433104    \n",
            "\n",
            " 285                        -1.73331                              -2.03914                -1.8011          -1.52665             -1.2964                  -5.33215                 -5.29742                       -1.38827                                         -1.82172       -4.99873     -1.2978      -0.967324    \n",
            "\n",
            " 286                        -2.16431                              -2.08114                -2.18647         -2.0773              -1.31372                 -5.91181                 -5.87948                       -1.28741                                         -2.14906       -5.67978     -1.95795     -1.45705     \n",
            "\n",
            " 287                        -1.50204                              -1.95182                -1.74543         -1.46294             -0.925812                -3.79632                 -3.75524                       -1.16333                                         -1.43154       -3.44282     -1.38944     -1.1813      \n",
            "\n",
            " 288                        -0.298484                              0.279683               -0.648387         0.163569            -0.74851                 -0.777826                -0.724252                      -1.10122                                         -0.513386      -0.724804    -0.165123     0.186043    \n",
            "\n",
            " 289                        -2.01898                              -2.41493                -2.23094         -2.07505             -1.37562                 -5.16908                 -5.13367                       -1.35126                                         -2.09007       -4.80713     -1.97787     -1.72905     \n",
            "\n",
            " 290                        -1.20855                              -2.06321                -1.64235         -1.26291             -0.91496                 -2.36801                 -2.32102                       -1.15705                                         -1.25175       -1.77873     -1.22864     -1.31398     \n",
            "\n",
            " 291                        -1.74958                              -2.34172                -2.08322         -1.83607             -1.32494                 -3.79217                 -3.75106                       -1.27889                                         -1.93814       -3.18939     -1.80606     -1.69369     \n",
            "\n",
            " 292                        -2.16431                              -2.04842                -2.17325         -2.05321             -1.39625                 -5.91181                 -5.87948                       -1.3903                                          -2.10627       -5.67978     -1.80732     -1.65419     \n",
            "\n",
            " 293                        -1.99626                              -1.6198                 -1.88314         -1.68881             -1.35016                 -5.6971                  -5.66388                       -1.3903                                          -1.92608       -5.42751     -1.331       -1.28351     \n",
            "\n",
            " 294                        -2.0657                               -2.34111                -2.18715         -2.04145             -1.37819                 -5.78582                 -5.75296                       -1.3903                                          -2.08867       -5.53175     -1.88063     -1.56257     \n",
            "\n",
            " 295                        -1.9807                               -2.1128                 -2.03791         -1.86057             -1.30103                 -5.67721                 -5.6439                        -1.32385                                         -2.01988       -5.40414     -1.71583     -1.24018     \n",
            "\n",
            " 296                        -1.73331                              -2.31318                -2.0322          -1.77638             -1.31743                 -4.02873                 -3.9886                        -1.29693                                         -1.91345       -3.46733     -1.72005     -1.55691     \n",
            "\n",
            " 297                        -2.15511                              -2.42398                -2.29239         -2.18144             -1.40031                 -5.90007                 -5.86768                       -1.3903                                          -2.16103       -5.66598     -2.03995     -1.72622     \n",
            "\n",
            " 298                        -1.15764                              -1.94572                -1.53562         -1.15979             -0.769395                -2.69618                 -2.65054                       -1.15368                                         -1.04831       -2.27951     -1.06441     -1.16122     \n",
            "\n",
            " 299                        -0.248369                             -0.554657               -0.734115        -0.00975252          -0.460711                -0.15958                 -0.103448                      -1.01085                                         -0.250124       0.143393    -0.171062    -0.228917    \n",
            "\n",
            " 300                        -1.89201                              -1.39411                -1.78877         -1.5789              -1.21635                 -5.04202                 -5.00609                       -1.3263                                          -1.71863       -4.76005     -1.20018     -1.37591     \n",
            "\n",
            " 301                        -2.16431                              -1.51819                -1.99431         -1.859               -1.36889                 -5.91181                 -5.87948                       -1.36726                                         -2.02879       -5.67978     -1.49255     -1.48568     \n",
            "\n",
            " 302                        -0.958805                             -0.180136               -1.08759         -0.509884            -0.967149                -2.52315                 -2.47679                       -1.196                                           -1.01851       -2.42229     -0.564165    -0.425606    \n",
            "\n",
            " 303                        -0.870296                             -1.85875                -1.35453         -0.892458            -0.652209                -1.50363                 -1.45306                       -1.08133                                         -0.810736      -0.932423    -0.845125    -1.06418     \n",
            "\n",
            " 304                        -1.64495                              -2.32699                -2.0137          -1.74087             -1.25396                 -3.48323                 -3.44085                       -1.25474                                         -1.82074       -2.87063     -1.72345     -1.63628     \n",
            "\n",
            " 305                        -2.16431                              -2.04988                -2.17374         -2.05375             -1.39627                 -5.91181                 -5.87948                       -1.3903                                          -2.1065        -5.67978     -1.80827     -1.65453     \n",
            "\n",
            " 306                        -2.02899                              -2.30709                -2.14395         -1.98399             -1.3691                  -5.73891                 -5.70586                       -1.3903                                          -2.05896       -5.47664     -1.81523     -1.49538     \n",
            "\n",
            " 307                        -0.212074                              0.597878               -0.811621        -0.437665            -1.29758                 -1.33871                 -1.28745                       -1.3466                                           0.0246473     -0.79525     -0.251483    -0.0208484   \n",
            "\n",
            " 308                         0.107932                              0.201677               -0.643317        -0.151341            -0.923099                -0.054581                 0.00198532                    -1.20599                                          0.341446       0.554912    -0.0615988    0.0191342   \n",
            "\n",
            " 309                        -2.16431                              -2.28209                -2.25371         -2.14773             -1.34614                 -5.91181                 -5.87948                       -1.32346                                         -2.16847       -5.67978     -2.04289     -1.57525     \n",
            "\n",
            " 310                        -0.715182                             -0.534191               -1.10159         -0.45529             -0.918407                -1.43247                 -1.3816                        -1.13777                                         -0.940359      -1.18117     -0.710481    -0.451084    \n",
            "\n",
            " 311                        -2.1112                               -1.48197                -1.95734         -1.80112             -1.37715                 -5.64039                 -5.60693                       -1.37604                                         -1.98691       -5.36088     -1.41557     -1.51952     \n",
            "\n",
            " 312                        -1.7937                               -1.93814                -1.81598         -1.55962             -1.30838                 -5.43828                 -5.40399                       -1.3903                                          -1.84412       -5.12342     -1.29819     -1.02985     \n",
            "\n",
            " 313                        -0.297205                             -1.12886                -0.898511        -0.351011            -0.476102                -0.313409                -0.257913                      -1.04274                                         -0.0957042      0.250814    -0.280338    -0.546744    \n",
            "\n",
            " 314                        -1.98059                              -1.64444                -1.87794         -1.67881             -1.34692                 -5.67707                 -5.64376                       -1.3903                                          -1.91974       -5.40397     -1.32847     -1.26388     \n",
            "\n",
            " 315                        -2.08236                              -1.48449                -1.91168         -1.74372             -1.36791                 -5.80711                 -5.77434                       -1.3903                                          -1.96092       -5.55676     -1.34495     -1.39133     \n",
            "\n",
            " 316                        -2.00866                              -2.41369                -2.22581         -2.06647             -1.3737                  -5.11631                 -5.08068                       -1.34849                                         -2.0845        -4.74513     -1.97229     -1.72805     \n",
            "\n",
            " 317                        -1.97977                              -2.41019                -2.21144         -2.04247             -1.36834                 -4.96868                 -4.93244                       -1.34073                                         -2.06891       -4.57168     -1.9567      -1.72527     \n",
            "\n",
            " 318                         0.203677                              0.986099               -0.431234         0.256089            -0.95006                  0.14586                  0.203256                      -1.18601                                          0.209529       0.463146     0.0842571    0.436362    \n",
            "\n",
            " 319                        -2.01391                              -2.24471                -2.1726          -2.01661             -1.31102                 -5.14315                 -5.10764                       -1.27452                                         -2.08733       -4.77667     -1.95998     -1.53935     \n",
            "\n",
            " 320                        -1.65565                              -2.33346                -2.0228          -1.75259             -1.26227                 -3.51058                 -3.46831                       -1.25714                                         -1.8347        -2.89741     -1.73558     -1.64418     \n",
            "\n",
            " 321                        -2.08166                              -2.42251                -2.26211         -2.12714             -1.38725                 -5.48943                 -5.45535                       -1.3681                                          -2.12388       -5.18352     -2.01171     -1.73509     \n",
            "\n",
            " 322                        -1.73331                              -2.3376                 -2.05279         -1.79864             -1.31931                 -3.91259                 -3.87198                       -1.28879                                         -1.92162       -3.33087     -1.75768     -1.60945     \n",
            "\n",
            " 323                        -1.77319                              -2.28558                -2.075           -1.83378             -1.32835                 -3.91286                 -3.87226                       -1.28524                                         -1.94132       -3.3312      -1.78056     -1.68232     \n",
            "\n",
            " 324                        -0.857866                             -1.73907                -1.24936         -0.776625            -0.633943                -2.00538                 -1.95689                       -1.11593                                         -0.756985      -1.52816     -0.658194    -0.813671    \n",
            "\n",
            " 325                        -1.73331                              -2.144                  -1.88953         -1.62221             -1.30445                 -4.8334                  -4.7966                        -1.35332                                         -1.85682       -4.41274     -1.45937     -1.19293     \n",
            "\n",
            " 326                        -1.84968                              -1.85016                -1.83454         -1.59532             -1.31993                 -5.50981                 -5.47581                       -1.3903                                          -1.86677       -5.20746     -1.30726     -1.09995     \n",
            "\n",
            " 327                        -1.9596                               -2.106                  -2.01727         -1.83162             -1.30059                 -5.65025                 -5.61684                       -1.32951                                         -2.00281       -5.37247     -1.67938     -1.2158      \n",
            "\n",
            " 328                        -1.97511                              -2.26347                -2.16103         -1.99186             -1.31262                 -4.94486                 -4.90853                       -1.27452                                         -2.0664        -4.5437      -1.94112     -1.56177     \n",
            "\n",
            " 329                         0.0525937                             0.0199375              -0.678174        -0.178614            -0.862043                -0.0899347               -0.0335146                     -1.18369                                          0.281735       0.513375    -0.0914768   -0.05816     \n",
            "\n",
            " 330                         0.0952213                             0.684819               -0.694615        -0.275593            -1.27734                 -0.438113                -0.383133                      -1.32364                                          0.283699       0.202314    -0.184793     0.130313    \n",
            "\n",
            " 331                        -2.16431                              -2.3382                 -2.27218         -2.16567             -1.3672                  -5.91181                 -5.87948                       -1.34839                                         -2.16847       -5.67978     -2.04791     -1.63785     \n",
            "\n",
            " 332                        -0.517325                             -0.342008               -1.16168         -0.798868            -1.2925                  -1.53385                 -1.4834                        -1.30719                                         -0.459867      -0.90116     -0.733791    -0.483342    \n",
            "\n",
            " 333                         0.3968                                1.204                  -0.444039         0.0321379           -1.23283                  0.14586                  0.203256                      -1.3157                                           0.626294       0.753063     0.105111     0.454965    \n",
            "\n",
            " 334                         0.109752                              0.880123               -0.425007         0.365008            -0.812532                 0.14586                  0.203256                      -1.12293                                          0.00683496     0.322144     0.0741147    0.427314    \n",
            "\n",
            " 335                        -2.16431                              -2.34736                -2.27519         -2.1686              -1.37064                 -5.91181                 -5.87948                       -1.35246                                         -2.16847       -5.67978     -2.04872     -1.64807     \n",
            "\n",
            " 336                        -1.34222                              -1.89869                -1.63151         -1.30618             -0.834347                -3.2858                  -3.2426                        -1.1365                                          -1.2537        -2.90298     -1.23411     -1.11587     \n",
            "\n",
            " 337                        -2.14192                              -1.40893                -1.94664         -1.79815             -1.38158                 -5.7974                  -5.76459                       -1.38429                                         -1.99106       -5.54535     -1.3824      -1.50473     \n",
            "\n",
            " 338                        -1.79022                              -1.94362                -1.81483         -1.55739             -1.30766                 -5.43383                 -5.39951                       -1.3903                                          -1.84271       -5.11819     -1.29763     -1.02548     \n",
            "\n",
            " 339                        -1.85101                              -2.32348                -2.124           -1.91271             -1.31774                 -4.3106                  -4.27164                       -1.27452                                         -1.99945       -3.7985      -1.88082     -1.6335      \n",
            "\n",
            " 340                        -1.90583                              -2.19294                -1.999           -1.79117             -1.33862                 -5.58155                 -5.54784                       -1.3903                                          -1.95929       -5.29174     -1.59579     -1.26997     \n",
            "\n",
            " 341                        -0.994122                             -0.841582               -1.20476         -0.653198            -1.01391                 -2.99991                 -2.95553                       -1.24137                                         -1.14671       -2.8134      -0.709721    -0.366784    \n",
            "\n",
            " 342                         0.370182                              1.17397                -0.442275         0.0630039           -1.19386                  0.14586                  0.203256                      -1.29783                                          0.568853       0.713106     0.102237     0.452401    \n",
            "\n",
            " 343                        -0.352473                             -1.12098                -0.872167        -0.233088            -0.383422                -0.292596                -0.237015                      -0.99687                                         -0.250124       0.143393    -0.272235    -0.509704    \n",
            "\n",
            " 344                        -2.02477                              -2.30318                -2.13899         -1.97738             -1.36806                 -5.73352                 -5.70045                       -1.3903                                          -2.05555       -5.47031     -1.80771     -1.48766     \n",
            "\n",
            " 345                        -1.78315                              -2.3563                 -2.10375         -1.86942             -1.32054                 -3.96373                 -3.92334                       -1.27452                                         -1.96283       -3.39096     -1.84784     -1.67273     \n",
            "\n",
            " 346                        -1.65952                              -1.4269                 -1.66063         -1.39355             -1.07251                 -4.29937                 -4.26036                       -1.27165                                         -1.48345       -3.97475     -1.06524     -1.27513     \n",
            "\n",
            " 347                        -1.73331                              -2.20154                -1.93806         -1.67465             -1.30886                 -4.5597                  -4.52177                       -1.33414                                         -1.87608       -4.09117     -1.54804     -1.31673     \n",
            "\n",
            " 348                        -0.475357                             -1.61062                -1.01053         -0.45134             -0.344701                -0.539154                -0.484593                      -0.996053                                        -0.292659       0.00311761  -0.382831    -0.752261    \n",
            "\n",
            " 349                        -1.00563                              -1.94056                -1.46969         -1.04068             -0.75734                 -1.84948                 -1.80034                       -1.11162                                         -0.987192      -1.27104     -0.998574    -1.16413     \n",
            "\n",
            " 350                         0.320053                              1.11741                -0.438951         0.121135            -1.12046                  0.14586                  0.203256                      -1.26416                                          0.460673       0.637851     0.0968237    0.447572    \n",
            "\n",
            " 351                        -1.74669                              -2.04545                -1.81171         -1.54204             -1.29924                 -5.37821                 -5.34367                       -1.3903                                          -1.83051       -5.05285     -1.31225     -0.978708    \n",
            "\n",
            " 352                        -0.995415                             -0.91503                -1.33361         -0.99913             -1.2868                  -3.47546                 -3.43305                       -1.37048                                         -0.963765      -3.03883     -0.810333    -0.470878    \n",
            "\n",
            " 353                        -1.84112                              -2.0678                 -1.9014          -1.66904             -1.29815                 -5.49887                 -5.46483                       -1.36134                                         -1.90693       -5.19461     -1.47468     -1.07884     \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeBsPnOvCU2X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNq4CiIbCUzh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RPehNuWgDuf"
      },
      "source": [
        "# Penentuan Parameter Optimal untuk SVM-RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fkCXbO-ij-X",
        "outputId": "d06cccce-5f12-49c7-8064-aedb5e9f1699"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# mendefinisikan range dari parameter\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'kernel': ['linear']}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "# fitting model untuk grid search\n",
        "\n",
        "grid.fit(X_train_res, y_train_res)\n",
        "# print parameter terbaik setelah tuning\n",
        "print(grid.best_params_)\n",
        "\n",
        "# print bagaimana model terlihat setelah hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.930, total=   0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.971, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.944, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=0.986, total=   0.0s\n",
            "{'C': 10, 'kernel': 'linear'}\n",
            "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D27v26ejey3"
      },
      "source": [
        "# Seleksi Fitur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxbM_Rfh70fE",
        "outputId": "70caccd7-7136-445c-9c48-1794542ccc4a"
      },
      "source": [
        "#PEMBENTUKAN SVM DENGAN KERNEL LINEAR DAN PARAMETER OPTIMAL C=10\n",
        "\n",
        "# import SVC classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# import metrics to compute accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# instantiate classifier with linear kernel and C=10\n",
        "linear_svc=SVC(kernel='linear', C=10) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc.fit(X_train_res, y_train_res)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred_test=linear_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=10 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n",
        "print ('coefficients',linear_svc.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy score with linear kernel and C=10 : 0.8936\n",
            "coefficients [[-0.68911227 -0.78892791  5.06172484 -3.4998017  -2.31041773  1.70847015\n",
            "   1.71553815  5.38416633  0.72207373 -2.90908343 -0.97514096  0.50053372]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwkIm6z15mPF",
        "outputId": "857b4fa8-f776-479a-b351-ebf441a750d9"
      },
      "source": [
        "# Proses seleksi fitur menggunakan SVM-RFE\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.feature_selection import RFE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# membuat proses rekursif dan memberi peringkat tiap fitur\n",
        "rfe = RFE(estimator=linear_svc, n_features_to_select=1, step=1)\n",
        "rfe.fit(X_train_res, y_train_res)\n",
        "# print ringkasan untuk atribut yang terpilih\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)\n",
        "# print berat bobot untuk fitur terpilih\n",
        "print ('coefficients',rfe.estimator_.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False False False False False  True False False False False]\n",
            "[10  9  3  4  2  8  5  1 11  6  7 12]\n",
            "coefficients [[7.35578382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKGYGUhLEKPc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "18faa0cf-f0bc-4e6d-aa82-afdcf266ac9e"
      },
      "source": [
        "# untuk melihat bentuk fitur pada data latih\n",
        "X_train_res = pd.DataFrame(X_train_res)\n",
        "X_train_res.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.009319</td>\n",
              "      <td>1.770466</td>\n",
              "      <td>2.662086</td>\n",
              "      <td>1.011214</td>\n",
              "      <td>0.703961</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.811401</td>\n",
              "      <td>2.598332</td>\n",
              "      <td>0.143393</td>\n",
              "      <td>3.854295</td>\n",
              "      <td>3.695699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.421679</td>\n",
              "      <td>-2.067782</td>\n",
              "      <td>-0.252793</td>\n",
              "      <td>0.519746</td>\n",
              "      <td>0.286206</td>\n",
              "      <td>0.696558</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>0.462182</td>\n",
              "      <td>0.505589</td>\n",
              "      <td>0.790413</td>\n",
              "      <td>-0.334336</td>\n",
              "      <td>-1.078772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.871314</td>\n",
              "      <td>-1.842002</td>\n",
              "      <td>-1.338728</td>\n",
              "      <td>-1.287860</td>\n",
              "      <td>-1.189267</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-1.100852</td>\n",
              "      <td>-0.947705</td>\n",
              "      <td>0.790413</td>\n",
              "      <td>0.619741</td>\n",
              "      <td>-0.123878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.852677</td>\n",
              "      <td>-0.157341</td>\n",
              "      <td>0.118711</td>\n",
              "      <td>-0.796391</td>\n",
              "      <td>-0.495972</td>\n",
              "      <td>0.696558</td>\n",
              "      <td>0.756232</td>\n",
              "      <td>-0.348280</td>\n",
              "      <td>-0.075728</td>\n",
              "      <td>0.790413</td>\n",
              "      <td>0.363769</td>\n",
              "      <td>-0.497532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.440317</td>\n",
              "      <td>-0.209444</td>\n",
              "      <td>-0.002742</td>\n",
              "      <td>0.902925</td>\n",
              "      <td>-0.451530</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.927181</td>\n",
              "      <td>0.389326</td>\n",
              "      <td>0.143393</td>\n",
              "      <td>-0.799739</td>\n",
              "      <td>-0.248430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        9         10        11\n",
              "0 -0.009319  1.770466  2.662086  ...  0.143393  3.854295  3.695699\n",
              "1  0.421679 -2.067782 -0.252793  ...  0.790413 -0.334336 -1.078772\n",
              "2 -0.871314 -1.842002 -1.338728  ...  0.790413  0.619741 -0.123878\n",
              "3  0.852677 -0.157341  0.118711  ...  0.790413  0.363769 -0.497532\n",
              "4 -0.440317 -0.209444 -0.002742  ...  0.143393 -0.799739 -0.248430\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q-LsNirFffq"
      },
      "source": [
        "# menghapus fitur yang tidak terpilih pada seleksi fitur dalam data latih\n",
        "X_train_res.drop(X_train_res.columns[[0, 1, 5, 8, 10, 11]], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1nuI8KcEGIXf",
        "outputId": "47882db1-8635-49c9-c1c2-c76044deaa0d"
      },
      "source": [
        "# hasil dari data train yang telah terpilih fiturnya\n",
        "X_train_res.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.662086</td>\n",
              "      <td>1.011214</td>\n",
              "      <td>0.703961</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.811401</td>\n",
              "      <td>0.143393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.252793</td>\n",
              "      <td>0.519746</td>\n",
              "      <td>0.286206</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>0.462182</td>\n",
              "      <td>0.790413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.338728</td>\n",
              "      <td>-1.287860</td>\n",
              "      <td>-1.189267</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-1.100852</td>\n",
              "      <td>0.790413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.118711</td>\n",
              "      <td>-0.796391</td>\n",
              "      <td>-0.495972</td>\n",
              "      <td>0.756232</td>\n",
              "      <td>-0.348280</td>\n",
              "      <td>0.790413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.002742</td>\n",
              "      <td>0.902925</td>\n",
              "      <td>-0.451530</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.927181</td>\n",
              "      <td>0.143393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          2         3         4         6         7         9\n",
              "0  2.662086  1.011214  0.703961  0.203256 -0.811401  0.143393\n",
              "1 -0.252793  0.519746  0.286206  0.203256  0.462182  0.790413\n",
              "2 -1.338728 -1.287860 -1.189267  0.203256 -1.100852  0.790413\n",
              "3  0.118711 -0.796391 -0.495972  0.756232 -0.348280  0.790413\n",
              "4 -0.002742  0.902925 -0.451530  0.203256 -0.927181  0.143393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "sQ1xijrRGL9k",
        "outputId": "aaf17ba8-7bb4-4968-b2e8-0114cb61aeca"
      },
      "source": [
        "# pada data uji juga dilakukan penghapusan fitur yang tidak terpilih pada seleksi fitur\n",
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>A submission has been submitted</th>\n",
              "      <th>Course activity completion updated</th>\n",
              "      <th>Course module viewed</th>\n",
              "      <th>Course viewed</th>\n",
              "      <th>Discussion viewed</th>\n",
              "      <th>Quiz attempt started</th>\n",
              "      <th>Quiz attempt submitted</th>\n",
              "      <th>Some content has been posted.</th>\n",
              "      <th>The status of the submission has been viewed</th>\n",
              "      <th>User graded</th>\n",
              "      <th>File</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.009319</td>\n",
              "      <td>-1.720429</td>\n",
              "      <td>-0.309947</td>\n",
              "      <td>-0.121663</td>\n",
              "      <td>-0.887062</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.927181</td>\n",
              "      <td>-0.133860</td>\n",
              "      <td>0.143393</td>\n",
              "      <td>-0.055094</td>\n",
              "      <td>-0.829670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.440317</td>\n",
              "      <td>1.110496</td>\n",
              "      <td>-0.502844</td>\n",
              "      <td>0.802965</td>\n",
              "      <td>-0.638187</td>\n",
              "      <td>0.145860</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.406170</td>\n",
              "      <td>-0.017597</td>\n",
              "      <td>0.143393</td>\n",
              "      <td>-0.939360</td>\n",
              "      <td>0.457362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.440317</td>\n",
              "      <td>0.137908</td>\n",
              "      <td>0.225876</td>\n",
              "      <td>0.236526</td>\n",
              "      <td>0.117327</td>\n",
              "      <td>-0.404837</td>\n",
              "      <td>-0.349720</td>\n",
              "      <td>1.504205</td>\n",
              "      <td>-0.657046</td>\n",
              "      <td>-0.503626</td>\n",
              "      <td>0.177608</td>\n",
              "      <td>-0.165395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.009319</td>\n",
              "      <td>-1.390444</td>\n",
              "      <td>-0.059896</td>\n",
              "      <td>-0.055023</td>\n",
              "      <td>-0.131548</td>\n",
              "      <td>0.696558</td>\n",
              "      <td>0.756232</td>\n",
              "      <td>-0.753511</td>\n",
              "      <td>-0.831441</td>\n",
              "      <td>1.437432</td>\n",
              "      <td>1.038604</td>\n",
              "      <td>-1.618495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.871314</td>\n",
              "      <td>0.797879</td>\n",
              "      <td>-0.002742</td>\n",
              "      <td>-0.379892</td>\n",
              "      <td>-0.655963</td>\n",
              "      <td>-0.404837</td>\n",
              "      <td>-0.349720</td>\n",
              "      <td>-1.158742</td>\n",
              "      <td>-0.308255</td>\n",
              "      <td>-0.503626</td>\n",
              "      <td>0.177608</td>\n",
              "      <td>0.955567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  A submission has been submitted  ...       URL\n",
              "0                       -0.009319  ... -0.829670\n",
              "1                       -0.440317  ...  0.457362\n",
              "2                       -0.440317  ... -0.165395\n",
              "3                       -0.009319  ... -1.618495\n",
              "4                       -0.871314  ...  0.955567\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv4s5hY8Knmn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "824d83f4-a81e-44de-fa6d-b7b1b162f64d"
      },
      "source": [
        "# penghapusan fitur pada data uji\n",
        "X_test.drop(X_test.columns[[0, 1, 5, 8, 10, 11]], axis=1, inplace=True)\n",
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Course module viewed</th>\n",
              "      <th>Course viewed</th>\n",
              "      <th>Discussion viewed</th>\n",
              "      <th>Quiz attempt submitted</th>\n",
              "      <th>Some content has been posted.</th>\n",
              "      <th>User graded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.309947</td>\n",
              "      <td>-0.121663</td>\n",
              "      <td>-0.887062</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.927181</td>\n",
              "      <td>0.143393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.502844</td>\n",
              "      <td>0.802965</td>\n",
              "      <td>-0.638187</td>\n",
              "      <td>0.203256</td>\n",
              "      <td>-0.406170</td>\n",
              "      <td>0.143393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.225876</td>\n",
              "      <td>0.236526</td>\n",
              "      <td>0.117327</td>\n",
              "      <td>-0.349720</td>\n",
              "      <td>1.504205</td>\n",
              "      <td>-0.503626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.059896</td>\n",
              "      <td>-0.055023</td>\n",
              "      <td>-0.131548</td>\n",
              "      <td>0.756232</td>\n",
              "      <td>-0.753511</td>\n",
              "      <td>1.437432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.002742</td>\n",
              "      <td>-0.379892</td>\n",
              "      <td>-0.655963</td>\n",
              "      <td>-0.349720</td>\n",
              "      <td>-1.158742</td>\n",
              "      <td>-0.503626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Course module viewed Course viewed  ... Some content has been posted. User graded\n",
              "0            -0.309947     -0.121663  ...                     -0.927181    0.143393\n",
              "1            -0.502844      0.802965  ...                     -0.406170    0.143393\n",
              "2             0.225876      0.236526  ...                      1.504205   -0.503626\n",
              "3            -0.059896     -0.055023  ...                     -0.753511    1.437432\n",
              "4            -0.002742     -0.379892  ...                     -1.158742   -0.503626\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNiE1r0lnjsS"
      },
      "source": [
        "# Klasifikasi menggunakan fitur terpilih dengan SVM dan fungsi Kernel RBF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9wmb9kFWDPp",
        "outputId": "0b2e6adf-f8ac-475a-cd64-29b40f769ccb"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# untuk mendefinisikan range dari parameter\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "\t\t\t'kernel': ['rbf']}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "# fitting model pada gridsearch\n",
        "\n",
        "grid.fit(X_train_res, y_train_res)\n",
        "# print parameter terbaik setelah tuning\n",
        "print(grid.best_params_)\n",
        "\n",
        "# print bagaimana model setelah hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.930, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.957, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.871, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.857, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.873, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.873, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.871, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.493, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.493, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.493, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.493, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.871, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.958, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.958, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.871, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.857, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.871, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.958, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.958, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.871, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.857, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.958, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.958, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.859, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.887, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.901, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.871, total=   0.0s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.958, total=   0.0s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.944, total=   0.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=1.000, total=   0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.958, total=   0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.986, total=   0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.972, total=   0.0s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=1.000, total=   0.0s\n",
            "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaqG0BUAn57R",
        "outputId": "c3e05caf-df46-49b4-cbe6-ea60f767678f"
      },
      "source": [
        "# instantiate classifier with rbf kernel and C=100\n",
        "svc=SVC(C=100, gamma=0.1) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train_res,y_train_res)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred2=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=100 : {0:0.4f}'. format(accuracy_score(y_test, y_pred2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy score with rbf kernel and C=100 : 0.9362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qFyVkQcosJa",
        "outputId": "fa100b63-288c-41e7-9045-0e0219abbd12"
      },
      "source": [
        "# hasil prediksi dari klasifikasi\n",
        "y_pred_train1 = svc.predict(X_train_res)\n",
        "\n",
        "y_pred_train1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrTltckjosJc",
        "outputId": "142f2235-000e-4c8f-ea24-621f2c869ef1"
      },
      "source": [
        "# akurasi dari model yang terbentuk pada data latih yang diuji pada data uji\n",
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train_res, y_pred_train1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training-set accuracy score: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h85W_zcosJd",
        "outputId": "bd2a8868-ee83-4edc-b321-2933b3bb0283"
      },
      "source": [
        "# print the scores on training and test set\n",
        "# untuk melihat apakah model overfitting\n",
        "print('Training set score: {:.4f}'.format(svc.score(X_train_res, y_train_res)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(svc.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 1.0000\n",
            "Test set score: 0.9362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXAjUJ__qWcQ"
      },
      "source": [
        "karena selisih training set score dan test score tidak begitu jauh, maka model tidak overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ4Cacp4osJe",
        "outputId": "dad2b8a9-93db-42ab-91a1-354a1156c6c9"
      },
      "source": [
        "#untuk melihat jumlah observasi pada tiap label data uji\n",
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    42\n",
              "0     5\n",
              "Name: Status Kelulusan, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z9kTsqWosJf",
        "outputId": "2c4682b5-e23a-4bd9-ba16-8cc37cb3c635"
      },
      "source": [
        "# Print Confusion Matrix dan membaginya menjadi 4 bagian\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred2)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  2]\n",
            " [ 1 41]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3UfEguE0bfr"
      },
      "source": [
        "# fungsi untuk plot confusion Matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = 'd' \n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1ESa6WS06fK"
      },
      "source": [
        "class_names=np.array(['0','1']) # Binary label, Class = 1 (lulus) and Class = 0 (tidak lulus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ru49PJP60oeT",
        "outputId": "2e413b96-7143-44e7-c7ba-05533f0fedae"
      },
      "source": [
        "import itertools\n",
        "cm = confusion_matrix(y_test, y_pred2)\n",
        "plot_confusion_matrix(cm,class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "NSk3fyM_osJf",
        "outputId": "19415515-4e60-4af9-f29f-3aac4d7de1c4"
      },
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative:0', 'Actual Positive:1'], \n",
        "                                 index=['Predict Negative:0', 'Predict Positive:1'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f14a3d37850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPixgI26osJg",
        "outputId": "c3847de5-93a0-4a5e-a5e5-5f8f8c020b0b"
      },
      "source": [
        "# hasil laporan klasifikasi\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.60      0.67         5\n",
            "           1       0.95      0.98      0.96        42\n",
            "\n",
            "    accuracy                           0.94        47\n",
            "   macro avg       0.85      0.79      0.82        47\n",
            "weighted avg       0.93      0.94      0.93        47\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T-rCspJosJg",
        "outputId": "0fee18e8-fffc-4a78-f609-331aa6c02957"
      },
      "source": [
        "TN = cm[0,0]\n",
        "FP = cm[1,0]\n",
        "TP = cm[1,1]\n",
        "FN = cm[0,1]\n",
        "# print akurasi dari klasifikasi pada data uji\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy : 0.9362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zoysbP6osJh",
        "outputId": "f3daa030-5e04-4f08-b30f-19248a302c38"
      },
      "source": [
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification error : {0:0.4f}'.format(classification_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification error : 0.0638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRqGNqitosJh",
        "outputId": "272591f5-60fa-4d02-a897-c9b9a07d849c"
      },
      "source": [
        "# print precision score\n",
        "\n",
        "precision = TP / float(TP + FP)\n",
        "\n",
        "\n",
        "print('Precision : {0:0.4f}'.format(precision))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision : 0.9762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg-ynmo9osJi",
        "outputId": "ac141721-2a9e-4575-c0bd-e4d8df001334"
      },
      "source": [
        "recall = TP / float(TP + FN)\n",
        "\n",
        "print('Recall or Sensitivity : {0:0.4f}'.format(recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall or Sensitivity : 0.9535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGM_QSXyosJi",
        "outputId": "0a56de61-8bb9-444e-f413-2b899e0a50a3"
      },
      "source": [
        "true_positive_rate = TP / float(TP + FN)\n",
        "\n",
        "\n",
        "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive Rate : 0.9535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mqPokufosJj",
        "outputId": "622ace45-df1d-4ab5-a0be-1776f6ecf400"
      },
      "source": [
        "false_positive_rate = FP / float(FP + TN)\n",
        "\n",
        "\n",
        "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive Rate : 0.2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbsF12l2osJj",
        "outputId": "890004c5-b668-49ef-bf74-8bed17f292b5"
      },
      "source": [
        "specificity = TN / float(TN + FP)\n",
        "\n",
        "print('Specificity : {0:0.4f}'.format(specificity))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Specificity : 0.7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fi0PaI_kjeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8ad337-0b50-4e67-b4c8-2ac3113a7164"
      },
      "source": [
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('F1-Score : {0:0.4f}'.format(F1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score : 0.9647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkpWxBH_cbhY"
      },
      "source": [
        "COBA KELUARIN BENTUK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BPbDTtacbNx",
        "outputId": "881bb9e8-034d-4499-8329-c1f468fc583f"
      },
      "source": [
        "print('b = ',svc.intercept_)\n",
        "print('Indices of support vectors = ', svc.support_)\n",
        "print('Support vectors = ', svc.support_vectors_)\n",
        "print('Number of support vectors for each class = ', svc.n_support_)\n",
        "print('Coefficients of the support vector in the decision function = ', svc.dual_coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b =  [2.98503957]\n",
            "Indices of support vectors =  [ 12  41 115 148 197 219 278 288 303 310 332   4   8  43  48  67  81 121\n",
            " 126 137]\n",
            "Support vectors =  [[-9.88656601e-01 -4.21541943e-01 -3.18204464e-01 -3.49719920e-01\n",
            "  -9.85071401e-01  1.43393462e-01]\n",
            " [-1.93884978e+00 -1.79598841e+00 -1.38481160e+00 -5.87947934e+00\n",
            "  -1.39030249e+00 -5.67978007e+00]\n",
            " [-4.17111830e-01  5.03085679e-01 -6.38186606e-01  2.03256022e-01\n",
            "  -1.04296156e+00  1.43393462e-01]\n",
            " [-2.30320958e+00 -2.19582738e+00 -1.40258839e+00 -5.87947934e+00\n",
            "  -1.39030249e+00 -5.67978007e+00]\n",
            " [-6.01477871e-01  2.04823946e-01 -5.34968374e-01  2.48798205e-02\n",
            "  -1.02428764e+00  1.43393462e-01]\n",
            " [-1.03087349e+00 -3.97929968e-01 -9.30963726e-01 -2.25817921e+00\n",
            "  -1.19757176e+00 -2.16064320e+00]\n",
            " [-4.19475385e-01  4.61748521e-01 -6.90381386e-01  2.03256022e-01\n",
            "  -1.06690134e+00  1.96906882e-01]\n",
            " [-6.48386922e-01  1.63568743e-01 -7.48509652e-01 -7.24251674e-01\n",
            "  -1.10122112e+00 -7.24803966e-01]\n",
            " [-1.35453100e+00 -8.92458368e-01 -6.52209270e-01 -1.45305778e+00\n",
            "  -1.08132695e+00 -9.32423185e-01]\n",
            " [-1.10159334e+00 -4.55290030e-01 -9.18406883e-01 -1.38160020e+00\n",
            "  -1.13777072e+00 -1.18117015e+00]\n",
            " [-1.16168457e+00 -7.98868129e-01 -1.29250039e+00 -1.48339978e+00\n",
            "  -1.30718758e+00 -9.01159931e-01]\n",
            " [-2.74187019e-03  9.02924651e-01 -4.51530356e-01  2.03256022e-01\n",
            "  -9.27181246e-01  1.43393462e-01]\n",
            " [-3.81390281e-01  9.49167288e-02 -6.91516963e-01  2.03256022e-01\n",
            "  -9.27181246e-01  1.43393462e-01]\n",
            " [-6.45729738e-01 -5.46491621e-01 -8.42619641e-01 -1.45567180e+00\n",
            "  -9.85071401e-01 -1.15064510e+00]\n",
            " [-6.74306977e-01  2.19866407e-01 -1.22659821e-01  2.03256022e-01\n",
            "  -6.95620624e-01  7.90412744e-01]\n",
            " [-9.17213505e-01  6.03045422e-01 -3.71534821e-01  2.03256022e-01\n",
            "  -6.95620624e-01  1.43393462e-01]\n",
            " [-1.07438832e+00 -9.29670636e-01 -1.34925803e+00  2.03256022e-01\n",
            "  -1.39030249e+00  1.43393462e-01]\n",
            " [-1.52772373e-01  2.36526365e-01 -8.24842855e-01  2.03256022e-01\n",
            "  -9.85071401e-01  1.43393462e-01]\n",
            " [-1.01008953e+00 -3.13252221e-01 -6.91516963e-01 -3.49719920e-01\n",
            "  -7.53510780e-01  1.43393462e-01]\n",
            " [-5.45709403e-01 -2.54942371e-01 -8.42619641e-01 -2.00864774e+00\n",
            "  -1.10085171e+00 -2.44468366e+00]]\n",
            "Number of support vectors for each class =  [11  9]\n",
            "Coefficients of the support vector in the decision function =  [[ -30.90628743   -0.76762192 -100.           -2.85167452  -40.99148389\n",
            "   -18.2596158  -100.           -0.85832056   -1.9594811    -1.55683433\n",
            "    -6.3651362    48.08922509   41.08893425   21.31172969    5.53701204\n",
            "    70.81124483   17.98716285   71.54013703   18.45750542    9.69350457]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4zvqDq1cR2A"
      },
      "source": [
        "# COBA KERNEL LINIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7fXLxMsYwUP",
        "outputId": "53f8065c-abc5-48ce-a096-a59e505d4485"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# untuk mendefinisikan range dari parameter\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "\t\t\t'kernel': ['linear']}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "# fitting model pada gridsearch\n",
        "\n",
        "grid.fit(X_train_res, y_train_res)\n",
        "# print parameter terbaik setelah tuning\n",
        "print(grid.best_params_)\n",
        "\n",
        "# print bagaimana model setelah hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.944, total=   0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.915, total=   0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.915, total=   0.0s\n",
            "[CV] C=0.1, kernel=linear ............................................\n",
            "[CV] ................ C=0.1, kernel=linear, score=0.971, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.944, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1, kernel=linear ..............................................\n",
            "[CV] .................. C=1, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=0.958, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=10, kernel=linear .............................................\n",
            "[CV] ................. C=10, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=100, kernel=linear ............................................\n",
            "[CV] ................ C=100, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=0.972, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=0.986, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=1.000, total=   0.0s\n",
            "[CV] C=1000, kernel=linear ...........................................\n",
            "[CV] ............... C=1000, kernel=linear, score=1.000, total=   0.0s\n",
            "{'C': 100, 'kernel': 'linear'}\n",
            "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opx12JNOeB2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc7fa38-9440-4b4c-b6b3-a4a4558967f9"
      },
      "source": [
        "# instantiate classifier with linear kernel and C=100\n",
        "svc_linear=SVC(kernel='linear', C=100) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc_linear.fit(X_train_res,y_train_res)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred3=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=100 : {0:0.4f}'. format(accuracy_score(y_test, y_pred3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy score with linear kernel and C=100 : 0.9149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OeHiulGZADS",
        "outputId": "94adfb7b-086e-4526-b37b-90039e5d4766"
      },
      "source": [
        "# hasil laporan klasifikasi\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.20      0.33         5\n",
            "           1       0.91      1.00      0.95        42\n",
            "\n",
            "    accuracy                           0.91        47\n",
            "   macro avg       0.96      0.60      0.64        47\n",
            "weighted avg       0.92      0.91      0.89        47\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5rpUfCxZs1j",
        "outputId": "de7886e1-7cd2-4838-9084-9b34b7f2d966"
      },
      "source": [
        "# Print Confusion Matrix dan membaginya menjadi 4 bagian\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred3)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  4]\n",
            " [ 0 42]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tZLKk1IZ2Kb",
        "outputId": "14f344f2-4212-4a90-b884-ed8e1e8105f7"
      },
      "source": [
        "TN = cm[0,0]\n",
        "FP = cm[1,0]\n",
        "TP = cm[1,1]\n",
        "FN = cm[0,1]\n",
        "# print akurasi dari klasifikasi pada data uji\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy : 0.9149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KyzV_Q9Z2Kd",
        "outputId": "a2ca08b4-25d9-43e3-daa5-86c60d3ccccb"
      },
      "source": [
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification error : {0:0.4f}'.format(classification_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification error : 0.0851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B2PJ8qnZ2Kd",
        "outputId": "fde745aa-8ca4-4c90-df77-587b489b039e"
      },
      "source": [
        "# print precision score\n",
        "\n",
        "precision = TP / float(TP + FP)\n",
        "\n",
        "\n",
        "print('Precision : {0:0.4f}'.format(precision))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision : 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmQU1yOBZ2Ke",
        "outputId": "879dda19-3a56-404b-8543-511a68c15e20"
      },
      "source": [
        "recall = TP / float(TP + FN)\n",
        "\n",
        "print('Recall or Sensitivity : {0:0.4f}'.format(recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall or Sensitivity : 0.9130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FLipuf9Z2Kf",
        "outputId": "c5c3414d-ec51-401f-8155-531c880e203b"
      },
      "source": [
        "true_positive_rate = TP / float(TP + FN)\n",
        "\n",
        "\n",
        "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive Rate : 0.9130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcRZlyJTZ2Kg",
        "outputId": "f3529fbd-9709-4992-aa38-1d841c2cfddb"
      },
      "source": [
        "false_positive_rate = FP / float(FP + TN)\n",
        "\n",
        "\n",
        "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive Rate : 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46u0HUM4Z2Kg",
        "outputId": "1e2b21cf-c41e-4b55-9468-1df35dd4e86b"
      },
      "source": [
        "specificity = TN / float(TN + FP)\n",
        "\n",
        "print('Specificity : {0:0.4f}'.format(specificity))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Specificity : 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzOOo_waZ2Kh",
        "outputId": "bda92ccd-5bbc-492a-ea81-303d138215d9"
      },
      "source": [
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('F1-Score : {0:0.4f}'.format(F1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score : 0.9545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpd99rwxaAGx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7-tRPU8cXHZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}